import 'dart:convert';
import 'dart:typed_data';

/// Base class for all content types in a message.
///
/// Multi-modality allows a single message to contain different types of data,
/// such as text, images, or audio.
sealed class LlamaContentPart {
  /// Base constructor for content parts.
  const LlamaContentPart();

  /// Converts the content part to a JSON object.
  Map<String, dynamic> toJson();
}

/// A part of a message containing plain text.
class LlamaTextContent extends LlamaContentPart {
  /// The raw text string.
  final String text;

  /// Creates a text content part.
  const LlamaTextContent(this.text);

  @override
  Map<String, dynamic> toJson() => {'type': 'text', 'text': text};
}

/// A part of a message containing image data for vision models.
///
/// The model must be loaded with a compatible multimodal projector (mmproj).
class LlamaImageContent extends LlamaContentPart {
  /// Raw RGB pixel data.
  ///
  /// For best performance, provide pre-processed RGB bytes.
  final Uint8List? bytes; // RGB format

  /// Width of the image in pixels.
  final int? width;

  /// Height of the image in pixels.
  final int? height;

  /// Local filesystem path to the image (e.g., JPEG, PNG).
  ///
  /// If provided, the native engine will load and decode the image automatically.
  final String? path; // Alternative: file path

  /// URL to a remote image (not yet supported).
  final String? url; // Future: remote images

  /// Creates an image content part.
  ///
  /// Either [path] or [bytes] should be provided.
  const LlamaImageContent({
    this.bytes,
    this.width,
    this.height,
    this.path,
    this.url,
  });

  @override
  Map<String, dynamic> toJson() {
    return {
      'type': 'image_url',
      'image_url': {
        'url':
            url ??
            (path != null
                ? 'file://$path'
                : (bytes != null
                      ? 'data:image/jpeg;base64,${base64Encode(bytes!)}'
                      : '')),
      },
    };
  }
}

/// A part of a message containing audio data for speech-to-text models.
class LlamaAudioContent extends LlamaContentPart {
  /// Raw PCM Float32 audio samples.
  final Float32List? samples; // PCM F32

  /// Local filesystem path to the audio file (e.g., WAV, MP3).
  ///
  /// If provided, the native engine will decode the audio automatically.
  final String? path; // Alternative: file path

  /// Creates an audio content part.
  const LlamaAudioContent({this.samples, this.path});

  @override
  Map<String, dynamic> toJson() {
    return {
      'type': 'input_audio', // OpenAI draft format
      'input_audio': {
        'data': samples != null
            ? base64Encode(samples!.buffer.asUint8List())
            : '',
        'format': 'pcm', // Changed to pcm since we are sending raw samples
      },
    };
  }
}

/// A part of a message containing a tool call solicitation from the model.
class LlamaToolCallContent extends LlamaContentPart {
  /// Unique identifier for this call (if provided by the template/model).
  final String? id;

  /// The name of the function to be called.
  final String name;

  /// The arguments for the function as a Map.
  final Map<String, dynamic> arguments;

  /// The raw JSON string generated by the model.
  final String rawJson;

  /// Creates a tool call content part.
  const LlamaToolCallContent({
    required this.name,
    required this.arguments,
    required this.rawJson,
    this.id,
  });

  @override
  Map<String, dynamic> toJson() {
    // Tool calls are handled specially in message serialization,
    // but if treated as content part, we return null or special type?
    // For now return proper structure just in case.
    return {
      'type': 'function',
      'function': {'name': name, 'arguments': rawJson},
      'id': id,
    };
  }
}

/// A part of a message containing the result of a tool execution.
class LlamaToolResultContent extends LlamaContentPart {
  /// The ID of the tool call this result corresponds to.
  final String? id;

  /// The name of the function that was called.
  final String name;

  /// The result of the function execution (e.g., String, Map, List).
  final Object? result;

  /// Creates a tool result content part.
  const LlamaToolResultContent({
    required this.name,
    required this.result,
    this.id,
  });

  @override
  Map<String, dynamic> toJson() {
    return {
      'type': 'tool_result', // Internal use?
      'tool_call_id': id,
      'content': result.toString(),
    };
  }
}

/// A part of a message containing the model's Chain-of-Thought (reasoning).
///
/// This is typically used by reasoning models (e.g. DeepSeek-R1) to expose
/// their internal thought process before the final answer.
class LlamaThinkingContent extends LlamaContentPart {
  /// The thinking process text.
  final String thinking;

  /// Creates a thinking content part.
  const LlamaThinkingContent(this.thinking);

  @override
  Map<String, dynamic> toJson() {
    return {'type': 'thinking', 'thinking': thinking};
  }
}
