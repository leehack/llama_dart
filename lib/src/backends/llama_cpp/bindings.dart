// coverage:ignore-file
// ignore_for_file: always_specify_types, unused_field
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names
/// @nodoc

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint, unused_import
@ffi.DefaultAsset('package:llamadart/llamadart')
library;

import 'dart:ffi' as ffi;

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Int)>(
  symbol: 'llama_flash_attn_type_name',
)
external ffi.Pointer<ffi.Char> _llama_flash_attn_type_name(int flash_attn_type);

ffi.Pointer<ffi.Char> llama_flash_attn_type_name(
  llama_flash_attn_type flash_attn_type,
) => _llama_flash_attn_type_name(flash_attn_type.value);

@ffi.Native<llama_model_params Function()>()
external llama_model_params llama_model_default_params();

@ffi.Native<llama_context_params Function()>()
external llama_context_params llama_context_default_params();

@ffi.Native<llama_sampler_chain_params Function()>()
external llama_sampler_chain_params llama_sampler_chain_default_params();

@ffi.Native<llama_model_quantize_params Function()>()
external llama_model_quantize_params llama_model_quantize_default_params();

@ffi.Native<ffi.Void Function()>()
external void llama_backend_init();

@ffi.Native<ffi.Void Function()>()
external void llama_backend_free();

@ffi.Native<ffi.Void Function(ffi.UnsignedInt)>(symbol: 'llama_numa_init')
external void _llama_numa_init(int numa);

void llama_numa_init(ggml_numa_strategy numa) => _llama_numa_init(numa.value);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<llama_context>,
    ggml_threadpool_t,
    ggml_threadpool_t,
  )
>()
external void llama_attach_threadpool(
  ffi.Pointer<llama_context> ctx,
  ggml_threadpool_t threadpool,
  ggml_threadpool_t threadpool_batch,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_detach_threadpool(ffi.Pointer<llama_context> ctx);

@ffi.Native<
  ffi.Pointer<llama_model> Function(ffi.Pointer<ffi.Char>, llama_model_params)
>()
external ffi.Pointer<llama_model> llama_load_model_from_file(
  ffi.Pointer<ffi.Char> path_model,
  llama_model_params params,
);

@ffi.Native<
  ffi.Pointer<llama_model> Function(ffi.Pointer<ffi.Char>, llama_model_params)
>()
external ffi.Pointer<llama_model> llama_model_load_from_file(
  ffi.Pointer<ffi.Char> path_model,
  llama_model_params params,
);

@ffi.Native<
  ffi.Pointer<llama_model> Function(
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Size,
    llama_model_params,
  )
>()
external ffi.Pointer<llama_model> llama_model_load_from_splits(
  ffi.Pointer<ffi.Pointer<ffi.Char>> paths,
  int n_paths,
  llama_model_params params,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>)
>()
external void llama_model_save_to_file(
  ffi.Pointer<llama_model> model,
  ffi.Pointer<ffi.Char> path_model,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_model>)>()
external void llama_free_model(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_model>)>()
external void llama_model_free(ffi.Pointer<llama_model> model);

@ffi.Native<
  ffi.Pointer<llama_context> Function(
    ffi.Pointer<llama_model>,
    llama_context_params,
  )
>()
external ffi.Pointer<llama_context> llama_init_from_model(
  ffi.Pointer<llama_model> model,
  llama_context_params params,
);

@ffi.Native<
  ffi.Pointer<llama_context> Function(
    ffi.Pointer<llama_model>,
    llama_context_params,
  )
>()
external ffi.Pointer<llama_context> llama_new_context_with_model(
  ffi.Pointer<llama_model> model,
  llama_context_params params,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_free(ffi.Pointer<llama_context> ctx);

@ffi.Native<
  ffi.UnsignedInt Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_model_params>,
    ffi.Pointer<llama_context_params>,
    ffi.Pointer<ffi.Float>,
    ffi.Pointer<llama_model_tensor_buft_override>,
    ffi.Pointer<ffi.Size>,
    ffi.Uint32,
    ffi.UnsignedInt,
  )
>(symbol: 'llama_params_fit')
external int _llama_params_fit(
  ffi.Pointer<ffi.Char> path_model,
  ffi.Pointer<llama_model_params> mparams,
  ffi.Pointer<llama_context_params> cparams,
  ffi.Pointer<ffi.Float> tensor_split,
  ffi.Pointer<llama_model_tensor_buft_override> tensor_buft_overrides,
  ffi.Pointer<ffi.Size> margins,
  int n_ctx_min,
  int log_level,
);

llama_params_fit_status llama_params_fit(
  ffi.Pointer<ffi.Char> path_model,
  ffi.Pointer<llama_model_params> mparams,
  ffi.Pointer<llama_context_params> cparams,
  ffi.Pointer<ffi.Float> tensor_split,
  ffi.Pointer<llama_model_tensor_buft_override> tensor_buft_overrides,
  ffi.Pointer<ffi.Size> margins,
  int n_ctx_min,
  ggml_log_level log_level,
) => llama_params_fit_status.fromValue(
  _llama_params_fit(
    path_model,
    mparams,
    cparams,
    tensor_split,
    tensor_buft_overrides,
    margins,
    n_ctx_min,
    log_level.value,
  ),
);

@ffi.Native<ffi.Int64 Function()>()
external int llama_time_us();

@ffi.Native<ffi.Size Function()>()
external int llama_max_devices();

@ffi.Native<ffi.Size Function()>()
external int llama_max_parallel_sequences();

@ffi.Native<ffi.Size Function()>()
external int llama_max_tensor_buft_overrides();

@ffi.Native<ffi.Bool Function()>()
external bool llama_supports_mmap();

@ffi.Native<ffi.Bool Function()>()
external bool llama_supports_mlock();

@ffi.Native<ffi.Bool Function()>()
external bool llama_supports_gpu_offload();

@ffi.Native<ffi.Bool Function()>()
external bool llama_supports_rpc();

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_ctx(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_ctx_seq(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_batch(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_ubatch(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_seq_max(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_n_ctx_train(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_n_embd(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_n_layer(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_n_head(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_vocab>)>()
external int llama_n_vocab(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Pointer<llama_model> Function(ffi.Pointer<llama_context>)>()
external ffi.Pointer<llama_model> llama_get_model(
  ffi.Pointer<llama_context> ctx,
);

@ffi.Native<llama_memory_t Function(ffi.Pointer<llama_context>)>()
external llama_memory_t llama_get_memory(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Int Function(ffi.Pointer<llama_context>)>(
  symbol: 'llama_pooling_type',
)
external int _llama_pooling_type$1(ffi.Pointer<llama_context> ctx);

llama_pooling_type llama_pooling_type$1(ffi.Pointer<llama_context> ctx) =>
    llama_pooling_type.fromValue(_llama_pooling_type$1(ctx));

@ffi.Native<ffi.Pointer<llama_vocab> Function(ffi.Pointer<llama_model>)>()
external ffi.Pointer<llama_vocab> llama_model_get_vocab(
  ffi.Pointer<llama_model> model,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<llama_model>)>(
  symbol: 'llama_model_rope_type',
)
external int _llama_model_rope_type(ffi.Pointer<llama_model> model);

llama_rope_type llama_model_rope_type(ffi.Pointer<llama_model> model) =>
    llama_rope_type.fromValue(_llama_model_rope_type(model));

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_ctx_train(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_embd(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_embd_inp(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_embd_out(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_layer(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_head(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_head_kv(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_swa(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Float Function(ffi.Pointer<llama_model>)>()
external double llama_model_rope_freq_scale_train(
  ffi.Pointer<llama_model> model,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_cls_out(ffi.Pointer<llama_model> model);

@ffi.Native<
  ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_model>, ffi.Uint32)
>()
external ffi.Pointer<ffi.Char> llama_model_cls_label(
  ffi.Pointer<llama_model> model,
  int i,
);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>)>(
  symbol: 'llama_vocab_type',
)
external int _llama_vocab_type$1(ffi.Pointer<llama_vocab> vocab);

llama_vocab_type llama_vocab_type$1(ffi.Pointer<llama_vocab> vocab) =>
    llama_vocab_type.fromValue(_llama_vocab_type$1(vocab));

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_n_tokens(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_model>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_model_meta_val_str(
  ffi.Pointer<llama_model> model,
  ffi.Pointer<ffi.Char> key,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_model>)>()
external int llama_model_meta_count(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'llama_model_meta_key_str',
)
external ffi.Pointer<ffi.Char> _llama_model_meta_key_str(int key);

ffi.Pointer<ffi.Char> llama_model_meta_key_str(llama_model_meta_key key) =>
    _llama_model_meta_key_str(key.value);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_model>,
    ffi.Int32,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_model_meta_key_by_index(
  ffi.Pointer<llama_model> model,
  int i,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_model>,
    ffi.Int32,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_model_meta_val_str_by_index(
  ffi.Pointer<llama_model> model,
  int i,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<
  ffi.Int32 Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, ffi.Size)
>()
external int llama_model_desc(
  ffi.Pointer<llama_model> model,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<ffi.Uint64 Function(ffi.Pointer<llama_model>)>()
external int llama_model_size(ffi.Pointer<llama_model> model);

@ffi.Native<
  ffi.Pointer<ffi.Char> Function(
    ffi.Pointer<llama_model>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<ffi.Char> llama_model_chat_template(
  ffi.Pointer<llama_model> model,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ffi.Uint64 Function(ffi.Pointer<llama_model>)>()
external int llama_model_n_params(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_model>)>()
external bool llama_model_has_encoder(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_model>)>()
external bool llama_model_has_decoder(ffi.Pointer<llama_model> model);

@ffi.Native<llama_token Function(ffi.Pointer<llama_model>)>()
external int llama_model_decoder_start_token(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_model>)>()
external bool llama_model_is_recurrent(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_model>)>()
external bool llama_model_is_hybrid(ffi.Pointer<llama_model> model);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_model>)>()
external bool llama_model_is_diffusion(ffi.Pointer<llama_model> model);

@ffi.Native<
  ffi.Uint32 Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_model_quantize_params>,
  )
>()
external int llama_model_quantize(
  ffi.Pointer<ffi.Char> fname_inp,
  ffi.Pointer<ffi.Char> fname_out,
  ffi.Pointer<llama_model_quantize_params> params,
);

@ffi.Native<
  ffi.Pointer<llama_adapter_lora> Function(
    ffi.Pointer<llama_model>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<llama_adapter_lora> llama_adapter_lora_init(
  ffi.Pointer<llama_model> model,
  ffi.Pointer<ffi.Char> path_lora,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_adapter_lora>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_adapter_meta_val_str(
  ffi.Pointer<llama_adapter_lora> adapter,
  ffi.Pointer<ffi.Char> key,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_adapter_lora>)>()
external int llama_adapter_meta_count(ffi.Pointer<llama_adapter_lora> adapter);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_adapter_lora>,
    ffi.Int32,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_adapter_meta_key_by_index(
  ffi.Pointer<llama_adapter_lora> adapter,
  int i,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_adapter_lora>,
    ffi.Int32,
    ffi.Pointer<ffi.Char>,
    ffi.Size,
  )
>()
external int llama_adapter_meta_val_str_by_index(
  ffi.Pointer<llama_adapter_lora> adapter,
  int i,
  ffi.Pointer<ffi.Char> buf,
  int buf_size,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_adapter_lora>)>()
external void llama_adapter_lora_free(ffi.Pointer<llama_adapter_lora> adapter);

@ffi.Native<ffi.Uint64 Function(ffi.Pointer<llama_adapter_lora>)>()
external int llama_adapter_get_alora_n_invocation_tokens(
  ffi.Pointer<llama_adapter_lora> adapter,
);

@ffi.Native<
  ffi.Pointer<llama_token> Function(ffi.Pointer<llama_adapter_lora>)
>()
external ffi.Pointer<llama_token> llama_adapter_get_alora_invocation_tokens(
  ffi.Pointer<llama_adapter_lora> adapter,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<llama_adapter_lora>,
    ffi.Float,
  )
>()
external int llama_set_adapter_lora(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<llama_adapter_lora> adapter,
  double scale,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<llama_adapter_lora>,
  )
>()
external int llama_rm_adapter_lora(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<llama_adapter_lora> adapter,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_clear_adapter_lora(ffi.Pointer<llama_context> ctx);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Float>,
    ffi.Size,
    ffi.Int32,
    ffi.Int32,
    ffi.Int32,
  )
>()
external int llama_apply_adapter_cvec(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Float> data,
  int len,
  int n_embd,
  int il_start,
  int il_end,
);

@ffi.Native<ffi.Void Function(llama_memory_t, ffi.Bool)>()
external void llama_memory_clear(llama_memory_t mem, bool data);

@ffi.Native<
  ffi.Bool Function(llama_memory_t, llama_seq_id, llama_pos, llama_pos)
>()
external bool llama_memory_seq_rm(
  llama_memory_t mem,
  int seq_id,
  int p0,
  int p1,
);

@ffi.Native<
  ffi.Void Function(
    llama_memory_t,
    llama_seq_id,
    llama_seq_id,
    llama_pos,
    llama_pos,
  )
>()
external void llama_memory_seq_cp(
  llama_memory_t mem,
  int seq_id_src,
  int seq_id_dst,
  int p0,
  int p1,
);

@ffi.Native<ffi.Void Function(llama_memory_t, llama_seq_id)>()
external void llama_memory_seq_keep(llama_memory_t mem, int seq_id);

@ffi.Native<
  ffi.Void Function(
    llama_memory_t,
    llama_seq_id,
    llama_pos,
    llama_pos,
    llama_pos,
  )
>()
external void llama_memory_seq_add(
  llama_memory_t mem,
  int seq_id,
  int p0,
  int p1,
  int delta,
);

@ffi.Native<
  ffi.Void Function(llama_memory_t, llama_seq_id, llama_pos, llama_pos, ffi.Int)
>()
external void llama_memory_seq_div(
  llama_memory_t mem,
  int seq_id,
  int p0,
  int p1,
  int d,
);

@ffi.Native<llama_pos Function(llama_memory_t, llama_seq_id)>()
external int llama_memory_seq_pos_min(llama_memory_t mem, int seq_id);

@ffi.Native<llama_pos Function(llama_memory_t, llama_seq_id)>()
external int llama_memory_seq_pos_max(llama_memory_t mem, int seq_id);

@ffi.Native<ffi.Bool Function(llama_memory_t)>()
external bool llama_memory_can_shift(llama_memory_t mem);

@ffi.Native<ffi.Size Function(ffi.Pointer<llama_context>)>()
external int llama_state_get_size(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Size Function(ffi.Pointer<llama_context>)>()
external int llama_get_state_size(ffi.Pointer<llama_context> ctx);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
  )
>()
external int llama_state_get_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> dst,
  int size,
);

@ffi.Native<
  ffi.Size Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
>()
external int llama_copy_state_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> dst,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
  )
>()
external int llama_state_set_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> src,
  int size,
);

@ffi.Native<
  ffi.Size Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)
>()
external int llama_set_state_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> src,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_token>,
    ffi.Size,
    ffi.Pointer<ffi.Size>,
  )
>()
external bool llama_state_load_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> path_session,
  ffi.Pointer<llama_token> tokens_out,
  int n_token_capacity,
  ffi.Pointer<ffi.Size> n_token_count_out,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_token>,
    ffi.Size,
    ffi.Pointer<ffi.Size>,
  )
>()
external bool llama_load_session_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> path_session,
  ffi.Pointer<llama_token> tokens_out,
  int n_token_capacity,
  ffi.Pointer<ffi.Size> n_token_count_out,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_token>,
    ffi.Size,
  )
>()
external bool llama_state_save_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> path_session,
  ffi.Pointer<llama_token> tokens,
  int n_token_count,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_token>,
    ffi.Size,
  )
>()
external bool llama_save_session_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> path_session,
  ffi.Pointer<llama_token> tokens,
  int n_token_count,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<llama_context>, llama_seq_id)>()
external int llama_state_seq_get_size(
  ffi.Pointer<llama_context> ctx,
  int seq_id,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
    llama_seq_id,
  )
>()
external int llama_state_seq_get_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> dst,
  int size,
  int seq_id,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
    llama_seq_id,
  )
>()
external int llama_state_seq_set_data(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> src,
  int size,
  int dest_seq_id,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    llama_seq_id,
    ffi.Pointer<llama_token>,
    ffi.Size,
  )
>()
external int llama_state_seq_save_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> filepath,
  int seq_id,
  ffi.Pointer<llama_token> tokens,
  int n_token_count,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Char>,
    llama_seq_id,
    ffi.Pointer<llama_token>,
    ffi.Size,
    ffi.Pointer<ffi.Size>,
  )
>()
external int llama_state_seq_load_file(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Char> filepath,
  int dest_seq_id,
  ffi.Pointer<llama_token> tokens_out,
  int n_token_capacity,
  ffi.Pointer<ffi.Size> n_token_count_out,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    llama_seq_id,
    llama_state_seq_flags,
  )
>()
external int llama_state_seq_get_size_ext(
  ffi.Pointer<llama_context> ctx,
  int seq_id,
  int flags,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
    llama_seq_id,
    llama_state_seq_flags,
  )
>()
external int llama_state_seq_get_data_ext(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> dst,
  int size,
  int seq_id,
  int flags,
);

@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<ffi.Uint8>,
    ffi.Size,
    llama_seq_id,
    llama_state_seq_flags,
  )
>()
external int llama_state_seq_set_data_ext(
  ffi.Pointer<llama_context> ctx,
  ffi.Pointer<ffi.Uint8> src,
  int size,
  int dest_seq_id,
  int flags,
);

@ffi.Native<llama_batch Function(ffi.Pointer<llama_token>, ffi.Int32)>()
external llama_batch llama_batch_get_one(
  ffi.Pointer<llama_token> tokens,
  int n_tokens,
);

@ffi.Native<llama_batch Function(ffi.Int32, ffi.Int32, ffi.Int32)>()
external llama_batch llama_batch_init(int n_tokens, int embd, int n_seq_max);

@ffi.Native<ffi.Void Function(llama_batch)>()
external void llama_batch_free(llama_batch batch);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_context>, llama_batch)>()
external int llama_encode(ffi.Pointer<llama_context> ctx, llama_batch batch);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_context>, llama_batch)>()
external int llama_decode(ffi.Pointer<llama_context> ctx, llama_batch batch);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<llama_context>, ffi.Int32, ffi.Int32)
>()
external void llama_set_n_threads(
  ffi.Pointer<llama_context> ctx,
  int n_threads,
  int n_threads_batch,
);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_threads(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<llama_context>)>()
external int llama_n_threads_batch(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)>()
external void llama_set_embeddings(
  ffi.Pointer<llama_context> ctx,
  bool embeddings,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)>()
external void llama_set_causal_attn(
  ffi.Pointer<llama_context> ctx,
  bool causal_attn,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>, ffi.Bool)>()
external void llama_set_warmup(ffi.Pointer<llama_context> ctx, bool warmup);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<llama_context>,
    ggml_abort_callback,
    ffi.Pointer<ffi.Void>,
  )
>()
external void llama_set_abort_callback(
  ffi.Pointer<llama_context> ctx,
  ggml_abort_callback abort_callback,
  ffi.Pointer<ffi.Void> abort_callback_data,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_synchronize(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>()
external ffi.Pointer<ffi.Float> llama_get_logits(
  ffi.Pointer<llama_context> ctx,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
>()
external ffi.Pointer<ffi.Float> llama_get_logits_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>()
external ffi.Pointer<ffi.Float> llama_get_embeddings(
  ffi.Pointer<llama_context> ctx,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
>()
external ffi.Pointer<ffi.Float> llama_get_embeddings_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, llama_seq_id)
>()
external ffi.Pointer<ffi.Float> llama_get_embeddings_seq(
  ffi.Pointer<llama_context> ctx,
  int seq_id,
);

@ffi.Native<llama_token Function(ffi.Pointer<llama_context>, ffi.Int32)>()
external int llama_get_sampled_token_ith(ffi.Pointer<llama_context> ctx, int i);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
>()
external ffi.Pointer<ffi.Float> llama_get_sampled_probs_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>, ffi.Int32)>()
external int llama_get_sampled_probs_count_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<
  ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>, ffi.Int32)
>()
external ffi.Pointer<ffi.Float> llama_get_sampled_logits_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>, ffi.Int32)>()
external int llama_get_sampled_logits_count_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<
  ffi.Pointer<llama_token> Function(ffi.Pointer<llama_context>, ffi.Int32)
>()
external ffi.Pointer<llama_token> llama_get_sampled_candidates_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_context>, ffi.Int32)>()
external int llama_get_sampled_candidates_count_ith(
  ffi.Pointer<llama_context> ctx,
  int i,
);

@ffi.Native<
  ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, llama_token)
>()
external ffi.Pointer<ffi.Char> llama_vocab_get_text(
  ffi.Pointer<llama_vocab> vocab,
  int token,
);

@ffi.Native<ffi.Float Function(ffi.Pointer<llama_vocab>, llama_token)>()
external double llama_vocab_get_score(
  ffi.Pointer<llama_vocab> vocab,
  int token,
);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>, llama_token)>(
  symbol: 'llama_vocab_get_attr',
)
external int _llama_vocab_get_attr(ffi.Pointer<llama_vocab> vocab, int token);

llama_token_attr llama_vocab_get_attr(
  ffi.Pointer<llama_vocab> vocab,
  Dartllama_token token,
) => llama_token_attr.fromValue(_llama_vocab_get_attr(vocab, token));

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)>()
external bool llama_vocab_is_eog(ffi.Pointer<llama_vocab> vocab, int token);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)>()
external bool llama_vocab_is_control(ffi.Pointer<llama_vocab> vocab, int token);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_bos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_eos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_eot(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_sep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_nl(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_pad(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_mask(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>)>()
external bool llama_vocab_get_add_bos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>)>()
external bool llama_vocab_get_add_eos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>)>()
external bool llama_vocab_get_add_sep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_pre(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_suf(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_mid(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_pad(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_rep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_fim_sep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<
  ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_vocab>, llama_token)
>()
external ffi.Pointer<ffi.Char> llama_token_get_text(
  ffi.Pointer<llama_vocab> vocab,
  int token,
);

@ffi.Native<ffi.Float Function(ffi.Pointer<llama_vocab>, llama_token)>()
external double llama_token_get_score(
  ffi.Pointer<llama_vocab> vocab,
  int token,
);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<llama_vocab>, llama_token)>(
  symbol: 'llama_token_get_attr',
)
external int _llama_token_get_attr(ffi.Pointer<llama_vocab> vocab, int token);

llama_token_attr llama_token_get_attr(
  ffi.Pointer<llama_vocab> vocab,
  Dartllama_token token,
) => llama_token_attr.fromValue(_llama_token_get_attr(vocab, token));

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)>()
external bool llama_token_is_eog(ffi.Pointer<llama_vocab> vocab, int token);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>, llama_token)>()
external bool llama_token_is_control(ffi.Pointer<llama_vocab> vocab, int token);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_bos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_eos(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_eot(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_cls(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_sep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_nl(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_pad(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>)>()
external bool llama_add_bos_token(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<ffi.Bool Function(ffi.Pointer<llama_vocab>)>()
external bool llama_add_eos_token(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_pre(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_suf(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_mid(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_pad(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_rep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_token_fim_sep(ffi.Pointer<llama_vocab> vocab);

@ffi.Native<llama_token Function(ffi.Pointer<llama_vocab>)>()
external int llama_vocab_cls(ffi.Pointer<llama_vocab> vocab);

/// @details Convert the provided text into tokens.
/// @param tokens The tokens pointer must be large enough to hold the resulting tokens.
/// @return Returns the number of tokens on success, no more than n_tokens_max
/// @return Returns a negative number on failure - the number of tokens that would have been returned
/// @return Returns INT32_MIN on overflow (e.g., tokenization result size exceeds int32_t limit)
/// @param add_special Allow to add BOS and EOS tokens if model is configured to do so.
/// @param parse_special Allow tokenizing special and/or control tokens which otherwise are not exposed and treated
/// as plaintext. Does not insert a leading space.
@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_vocab>,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
    ffi.Pointer<llama_token>,
    ffi.Int32,
    ffi.Bool,
    ffi.Bool,
  )
>()
external int llama_tokenize(
  ffi.Pointer<llama_vocab> vocab,
  ffi.Pointer<ffi.Char> text,
  int text_len,
  ffi.Pointer<llama_token> tokens,
  int n_tokens_max,
  bool add_special,
  bool parse_special,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_vocab>,
    llama_token,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
    ffi.Int32,
    ffi.Bool,
  )
>()
external int llama_token_to_piece(
  ffi.Pointer<llama_vocab> vocab,
  int token,
  ffi.Pointer<ffi.Char> buf,
  int length,
  int lstrip,
  bool special,
);

/// @details Convert the provided tokens into text (inverse of llama_tokenize()).
/// @param text The char pointer must be large enough to hold the resulting text.
/// @return Returns the number of chars/bytes on success, no more than text_len_max.
/// @return Returns a negative number on failure - the number of chars/bytes that would have been returned.
/// @param remove_special Allow to remove BOS and EOS tokens if model is configured to do so.
/// @param unparse_special If true, special tokens are rendered in the output.
@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<llama_vocab>,
    ffi.Pointer<llama_token>,
    ffi.Int32,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
    ffi.Bool,
    ffi.Bool,
  )
>()
external int llama_detokenize(
  ffi.Pointer<llama_vocab> vocab,
  ffi.Pointer<llama_token> tokens,
  int n_tokens,
  ffi.Pointer<ffi.Char> text,
  int text_len_max,
  bool remove_special,
  bool unparse_special,
);

/// Apply chat template. Inspired by hf apply_chat_template() on python.
/// Both "model" and "custom_template" are optional, but at least one is required. "custom_template" has higher precedence than "model"
/// NOTE: This function does not use a jinja parser. It only support a pre-defined list of template. See more: https://github.com/ggml-org/llama.cpp/wiki/Templates-supported-by-llama_chat_apply_template
/// @param tmpl A Jinja template to use for this chat. If this is nullptr, the model’s default chat template will be used instead.
/// @param chat Pointer to a list of multiple llama_chat_message
/// @param n_msg Number of llama_chat_message in this chat
/// @param add_ass Whether to end the prompt with the token(s) that indicate the start of an assistant message.
/// @param buf A buffer to hold the output formatted prompt. The recommended alloc size is 2 * (total number of characters of all messages)
/// @param length The size of the allocated buffer
/// @return The total number of bytes of the formatted prompt. If is it larger than the size of buffer, you may need to re-alloc it and then re-apply the template.
@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_chat_message>,
    ffi.Size,
    ffi.Bool,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
  )
>()
external int llama_chat_apply_template(
  ffi.Pointer<ffi.Char> tmpl,
  ffi.Pointer<llama_chat_message> chat,
  int n_msg,
  bool add_ass,
  ffi.Pointer<ffi.Char> buf,
  int length,
);

@ffi.Native<ffi.Int32 Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Size)>()
external int llama_chat_builtin_templates(
  ffi.Pointer<ffi.Pointer<ffi.Char>> output,
  int len,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<llama_context>,
    llama_seq_id,
    ffi.Pointer<llama_sampler>,
  )
>()
external bool llama_set_sampler(
  ffi.Pointer<llama_context> ctx,
  int seq_id,
  ffi.Pointer<llama_sampler> smpl,
);

@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Pointer<llama_sampler_i>,
    llama_sampler_context_t,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init(
  ffi.Pointer<llama_sampler_i> iface,
  llama_sampler_context_t ctx,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_sampler>)>()
external ffi.Pointer<ffi.Char> llama_sampler_name(
  ffi.Pointer<llama_sampler> smpl,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_sampler>, llama_token)>()
external void llama_sampler_accept(ffi.Pointer<llama_sampler> smpl, int token);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<llama_sampler>,
    ffi.Pointer<llama_token_data_array>,
  )
>()
external void llama_sampler_apply(
  ffi.Pointer<llama_sampler> smpl,
  ffi.Pointer<llama_token_data_array> cur_p,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_sampler>)>()
external void llama_sampler_reset(ffi.Pointer<llama_sampler> smpl);

@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>)>()
external ffi.Pointer<llama_sampler> llama_sampler_clone(
  ffi.Pointer<llama_sampler> smpl,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_sampler>)>()
external void llama_sampler_free(ffi.Pointer<llama_sampler> smpl);

@ffi.Native<ffi.Pointer<llama_sampler> Function(llama_sampler_chain_params)>()
external ffi.Pointer<llama_sampler> llama_sampler_chain_init(
  llama_sampler_chain_params params,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<llama_sampler>, ffi.Pointer<llama_sampler>)
>()
external void llama_sampler_chain_add(
  ffi.Pointer<llama_sampler> chain,
  ffi.Pointer<llama_sampler> smpl,
);

@ffi.Native<
  ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>, ffi.Int32)
>()
external ffi.Pointer<llama_sampler> llama_sampler_chain_get(
  ffi.Pointer<llama_sampler> chain,
  int i,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<llama_sampler>)>()
external int llama_sampler_chain_n(ffi.Pointer<llama_sampler> chain);

@ffi.Native<
  ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler>, ffi.Int32)
>()
external ffi.Pointer<llama_sampler> llama_sampler_chain_remove(
  ffi.Pointer<llama_sampler> chain,
  int i,
);

@ffi.Native<ffi.Pointer<llama_sampler> Function()>()
external ffi.Pointer<llama_sampler> llama_sampler_init_greedy();

/// seed == LLAMA_DEFAULT_SEED to use a random seed.
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Uint32)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_dist(int seed);

/// @details Top-K sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
/// Setting k <= 0 makes this a noop
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Int32)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_top_k(int k);

/// @details Nucleus sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_top_p(
  double p,
  int min_keep,
);

/// @details Minimum P sampling as described in https://github.com/ggml-org/llama.cpp/pull/3841
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_min_p(
  double p,
  int min_keep,
);

/// @details Locally Typical Sampling implementation described in the paper https://arxiv.org/abs/2202.00666.
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Size)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_typical(
  double p,
  int min_keep,
);

/// #details Updates the logits l_i` = l_i/t. When t <= 0.0f, the maximum logit is kept at it's original value, the rest are set to -inf
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Float)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_temp(double t);

/// @details Dynamic temperature implementation (a.k.a. entropy) described in the paper https://arxiv.org/abs/2309.02772.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Float, ffi.Float)
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_temp_ext(
  double t,
  double delta,
  double exponent,
);

/// @details XTC sampler as described in https://github.com/oobabooga/text-generation-webui/pull/6335
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Float,
    ffi.Float,
    ffi.Size,
    ffi.Uint32,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_xtc(
  double p,
  double t,
  int min_keep,
  int seed,
);

/// @details Top n sigma sampling as described in academic paper "Top-nσ: Not All Logits Are You Need" https://arxiv.org/pdf/2411.07641
@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Float)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_top_n_sigma(double n);

/// @details Mirostat 1.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
/// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
/// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
/// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
/// @param m The number of tokens considered in the estimation of `s_hat`. This is an arbitrary value that is used to calculate `s_hat`, which in turn helps to calculate the value of `k`. In the paper, they use `m = 100`, but you can experiment with different values to see how it affects the performance of the algorithm.
/// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Int32,
    ffi.Uint32,
    ffi.Float,
    ffi.Float,
    ffi.Int32,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_mirostat(
  int n_vocab,
  int seed,
  double tau,
  double eta,
  int m,
);

/// @details Mirostat 2.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
/// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
/// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
/// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
/// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(ffi.Uint32, ffi.Float, ffi.Float)
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_mirostat_v2(
  int seed,
  double tau,
  double eta,
);

/// @details Intializes a GBNF grammar, see grammars/README.md for details.
/// @param vocab The vocabulary that this grammar will be used with.
/// @param grammar_str The production rules for the grammar, encoded as a string. Returns an empty grammar if empty. Returns NULL if parsing of grammar_str fails.
/// @param grammar_root The name of the start symbol for the grammar.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Pointer<llama_vocab>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_grammar(
  ffi.Pointer<llama_vocab> vocab,
  ffi.Pointer<ffi.Char> grammar_str,
  ffi.Pointer<ffi.Char> grammar_root,
);

@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Pointer<llama_vocab>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Size,
    ffi.Pointer<llama_token>,
    ffi.Size,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_grammar_lazy(
  ffi.Pointer<llama_vocab> vocab,
  ffi.Pointer<ffi.Char> grammar_str,
  ffi.Pointer<ffi.Char> grammar_root,
  ffi.Pointer<ffi.Pointer<ffi.Char>> trigger_words,
  int num_trigger_words,
  ffi.Pointer<llama_token> trigger_tokens,
  int num_trigger_tokens,
);

/// @details Lazy grammar sampler, introduced in https://github.com/ggml-org/llama.cpp/pull/9639
/// @param trigger_patterns A list of patterns that will trigger the grammar sampler. Pattern will be matched from the start of the generation output, and grammar sampler will be fed content starting from its first match group.
/// @param trigger_tokens A list of tokens that will trigger the grammar sampler. Grammar sampler will be fed content starting from the trigger token included.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Pointer<llama_vocab>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Size,
    ffi.Pointer<llama_token>,
    ffi.Size,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_grammar_lazy_patterns(
  ffi.Pointer<llama_vocab> vocab,
  ffi.Pointer<ffi.Char> grammar_str,
  ffi.Pointer<ffi.Char> grammar_root,
  ffi.Pointer<ffi.Pointer<ffi.Char>> trigger_patterns,
  int num_trigger_patterns,
  ffi.Pointer<llama_token> trigger_tokens,
  int num_trigger_tokens,
);

/// NOTE: Avoid using on the full vocabulary as searching for repeated tokens can become slow. For example, apply top-k or top-p sampling first.
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Int32,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_penalties(
  int penalty_last_n,
  double penalty_repeat,
  double penalty_freq,
  double penalty_present,
);

/// @details DRY sampler, designed by p-e-w, as described in: https://github.com/oobabooga/text-generation-webui/pull/5677, porting Koboldcpp implementation authored by pi6am: https://github.com/LostRuins/koboldcpp/pull/982
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Pointer<llama_vocab>,
    ffi.Int32,
    ffi.Float,
    ffi.Float,
    ffi.Int32,
    ffi.Int32,
    ffi.Pointer<ffi.Pointer<ffi.Char>>,
    ffi.Size,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_dry(
  ffi.Pointer<llama_vocab> vocab,
  int n_ctx_train,
  double dry_multiplier,
  double dry_base,
  int dry_allowed_length,
  int dry_penalty_last_n,
  ffi.Pointer<ffi.Pointer<ffi.Char>> seq_breakers,
  int num_breakers,
);

/// adaptive-p: select tokens near a configurable target probability over time.
///
/// the adaptive-p sampler transforms the token probability distribution to favor tokens
/// that fall near a user-configurable probability target.
///
/// internally, the sampler maintains an exponential moving average of the *ORIGINAL*
/// probabilities of selected tokens at each sampling step. it uses this EMA to compute an
/// adapted target probability at each sampling step, thus maintaining the desired target
/// probability over time.
///
/// adaptive-p selects a token ID rather than just mutating candidates, so it must be last
/// in the sampler chain (like mirostat, dist, greedy).
///
/// only mild truncation before this sampler is recommended. we suggest applying min-p
/// before adaptive-p as the only other active sampler in the chain.
///
/// @param target select tokens near this probability (valid range 0.0 to 1.0; negative = disabled)
/// @param decay  EMA decay for adaptation; history ≈ 1/(1-decay) tokens (valid range 0.0 - 0.99)
/// @param seed   RNG seed
///
/// ref: https://github.com/ggml-org/llama.cpp/pull/17927
@ffi.Native<
  ffi.Pointer<llama_sampler> Function(ffi.Float, ffi.Float, ffi.Uint32)
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_adaptive_p(
  double target,
  double decay,
  int seed,
);

@ffi.Native<
  ffi.Pointer<llama_sampler> Function(
    ffi.Int32,
    ffi.Int32,
    ffi.Pointer<llama_logit_bias>,
  )
>()
external ffi.Pointer<llama_sampler> llama_sampler_init_logit_bias(
  int n_vocab,
  int n_logit_bias,
  ffi.Pointer<llama_logit_bias> logit_bias,
);

@ffi.Native<ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_vocab>)>()
external ffi.Pointer<llama_sampler> llama_sampler_init_infill(
  ffi.Pointer<llama_vocab> vocab,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<llama_sampler>)>()
external int llama_sampler_get_seed(ffi.Pointer<llama_sampler> smpl);

@ffi.Native<
  llama_token Function(
    ffi.Pointer<llama_sampler>,
    ffi.Pointer<llama_context>,
    ffi.Int32,
  )
>()
external int llama_sampler_sample(
  ffi.Pointer<llama_sampler> smpl,
  ffi.Pointer<llama_context> ctx,
  int idx,
);

/// @details Build a split GGUF final path for this chunk.
/// llama_split_path(split_path, sizeof(split_path), "/models/ggml-model-q4_0", 2, 4) => split_path = "/models/ggml-model-q4_0-00002-of-00004.gguf"
@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<ffi.Char>,
    ffi.Size,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
    ffi.Int32,
  )
>()
external int llama_split_path(
  ffi.Pointer<ffi.Char> split_path,
  int maxlen,
  ffi.Pointer<ffi.Char> path_prefix,
  int split_no,
  int split_count,
);

/// @details Extract the path prefix from the split_path if and only if the split_no and split_count match.
/// llama_split_prefix(split_prefix, 64, "/models/ggml-model-q4_0-00002-of-00004.gguf", 2, 4) => split_prefix = "/models/ggml-model-q4_0"
@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<ffi.Char>,
    ffi.Size,
    ffi.Pointer<ffi.Char>,
    ffi.Int32,
    ffi.Int32,
  )
>()
external int llama_split_prefix(
  ffi.Pointer<ffi.Char> split_prefix,
  int maxlen,
  ffi.Pointer<ffi.Char> split_path,
  int split_no,
  int split_count,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> llama_print_system_info();

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_log_callback>,
    ffi.Pointer<ffi.Pointer<ffi.Void>>,
  )
>()
external void llama_log_get(
  ffi.Pointer<ggml_log_callback> log_callback,
  ffi.Pointer<ffi.Pointer<ffi.Void>> user_data,
);

@ffi.Native<ffi.Void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>()
external void llama_log_set(
  ggml_log_callback log_callback,
  ffi.Pointer<ffi.Void> user_data,
);

@ffi.Native<llama_perf_context_data Function(ffi.Pointer<llama_context>)>()
external llama_perf_context_data llama_perf_context(
  ffi.Pointer<llama_context> ctx,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_perf_context_print(ffi.Pointer<llama_context> ctx);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_perf_context_reset(ffi.Pointer<llama_context> ctx);

@ffi.Native<llama_perf_sampler_data Function(ffi.Pointer<llama_sampler>)>()
external llama_perf_sampler_data llama_perf_sampler(
  ffi.Pointer<llama_sampler> chain,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_sampler>)>()
external void llama_perf_sampler_print(ffi.Pointer<llama_sampler> chain);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_sampler>)>()
external void llama_perf_sampler_reset(ffi.Pointer<llama_sampler> chain);

@ffi.Native<ffi.Void Function(ffi.Pointer<llama_context>)>()
external void llama_memory_breakdown_print(ffi.Pointer<llama_context> ctx);

@ffi.Native<
  ffi.Bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Void>)
>()
external bool llama_opt_param_filter_all(
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<llama_context>,
    ffi.Pointer<llama_model>,
    llama_opt_params,
  )
>()
external void llama_opt_init(
  ffi.Pointer<llama_context> lctx,
  ffi.Pointer<llama_model> model,
  llama_opt_params lopt_params,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<llama_context>,
    ggml_opt_dataset_t,
    ggml_opt_result_t,
    ggml_opt_result_t,
    ffi.Int64,
    ggml_opt_epoch_callback,
    ggml_opt_epoch_callback,
  )
>()
external void llama_opt_epoch(
  ffi.Pointer<llama_context> lctx,
  ggml_opt_dataset_t dataset,
  ggml_opt_result_t result_train,
  ggml_opt_result_t result_eval,
  int idata_split,
  ggml_opt_epoch_callback callback_train,
  ggml_opt_epoch_callback callback_eval,
);

@ffi.Native<ggml_abort_callback_t Function(ggml_abort_callback_t)>()
external ggml_abort_callback_t ggml_set_abort_callback(
  ggml_abort_callback_t callback,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<ffi.Char>)
>()
external void ggml_abort(
  ffi.Pointer<ffi.Char> file,
  int line,
  ffi.Pointer<ffi.Char> fmt,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Int)>(
  symbol: 'ggml_status_to_string',
)
external ffi.Pointer<ffi.Char> _ggml_status_to_string(int status);

ffi.Pointer<ffi.Char> ggml_status_to_string(ggml_status status) =>
    _ggml_status_to_string(status.value);

@ffi.Native<ffi.Float Function(ggml_fp16_t)>()
external double ggml_fp16_to_fp32(int arg0);

@ffi.Native<ggml_fp16_t Function(ffi.Float)>()
external int ggml_fp32_to_fp16(double arg0);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_fp16_t>, ffi.Pointer<ffi.Float>, ffi.Int64)
>()
external void ggml_fp16_to_fp32_row(
  ffi.Pointer<ggml_fp16_t> arg0,
  ffi.Pointer<ffi.Float> arg1,
  int arg2,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_fp16_t>, ffi.Int64)
>()
external void ggml_fp32_to_fp16_row(
  ffi.Pointer<ffi.Float> arg0,
  ffi.Pointer<ggml_fp16_t> arg1,
  int arg2,
);

@ffi.Native<ggml_bf16_t Function(ffi.Float)>()
external ggml_bf16_t ggml_fp32_to_bf16(double arg0);

@ffi.Native<ffi.Float Function(ggml_bf16_t)>()
external double ggml_bf16_to_fp32(ggml_bf16_t arg0);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_bf16_t>, ffi.Pointer<ffi.Float>, ffi.Int64)
>()
external void ggml_bf16_to_fp32_row(
  ffi.Pointer<ggml_bf16_t> arg0,
  ffi.Pointer<ffi.Float> arg1,
  int arg2,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>, ffi.Int64)
>()
external void ggml_fp32_to_bf16_row_ref(
  ffi.Pointer<ffi.Float> arg0,
  ffi.Pointer<ggml_bf16_t> arg1,
  int arg2,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ggml_bf16_t>, ffi.Int64)
>()
external void ggml_fp32_to_bf16_row(
  ffi.Pointer<ffi.Float> arg0,
  ffi.Pointer<ggml_bf16_t> arg1,
  int arg2,
);

@ffi.Native<ffi.Size>()
external final int GGML_TENSOR_SIZE;

@ffi.Native<ffi.Bool Function(ggml_guid_t, ggml_guid_t)>()
external bool ggml_guid_matches(ggml_guid_t guid_a, ggml_guid_t guid_b);

@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> ggml_version();

@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> ggml_commit();

@ffi.Native<ffi.Void Function()>()
external void ggml_time_init();

@ffi.Native<ffi.Int64 Function()>()
external int ggml_time_ms();

@ffi.Native<ffi.Int64 Function()>()
external int ggml_time_us();

@ffi.Native<ffi.Int64 Function()>()
external int ggml_cycles();

@ffi.Native<ffi.Int64 Function()>()
external int ggml_cycles_per_ms();

@ffi.Native<
  ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)
>()
external ffi.Pointer<FILE> ggml_fopen(
  ffi.Pointer<ffi.Char> fname,
  ffi.Pointer<ffi.Char> mode,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_object>)>()
external void ggml_print_object(ffi.Pointer<ggml_object> obj);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_context>)>()
external void ggml_print_objects(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_nelements(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_nrows(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_nbytes(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_nbytes_pad(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Int64 Function(ffi.UnsignedInt)>(symbol: 'ggml_blck_size')
external int _ggml_blck_size(int type);

int ggml_blck_size(ggml_type type) => _ggml_blck_size(type.value);

@ffi.Native<ffi.Size Function(ffi.UnsignedInt)>(symbol: 'ggml_type_size')
external int _ggml_type_size(int type);

int ggml_type_size(ggml_type type) => _ggml_type_size(type.value);

@ffi.Native<ffi.Size Function(ffi.UnsignedInt, ffi.Int64)>(
  symbol: 'ggml_row_size',
)
external int _ggml_row_size(int type, int ne);

int ggml_row_size(ggml_type type, int ne) => _ggml_row_size(type.value, ne);

@ffi.Native<ffi.Double Function(ffi.UnsignedInt)>(symbol: 'ggml_type_sizef')
external double _ggml_type_sizef(int type);

double ggml_type_sizef(ggml_type type) => _ggml_type_sizef(type.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_type_name',
)
external ffi.Pointer<ffi.Char> _ggml_type_name(int type);

ffi.Pointer<ffi.Char> ggml_type_name(ggml_type type) =>
    _ggml_type_name(type.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_op_name',
)
external ffi.Pointer<ffi.Char> _ggml_op_name(int op);

ffi.Pointer<ffi.Char> ggml_op_name(ggml_op op) => _ggml_op_name(op.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_op_symbol',
)
external ffi.Pointer<ffi.Char> _ggml_op_symbol(int op);

ffi.Pointer<ffi.Char> ggml_op_symbol(ggml_op op) => _ggml_op_symbol(op.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_unary_op_name',
)
external ffi.Pointer<ffi.Char> _ggml_unary_op_name(int op);

ffi.Pointer<ffi.Char> ggml_unary_op_name(ggml_unary_op op) =>
    _ggml_unary_op_name(op.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_glu_op_name',
)
external ffi.Pointer<ffi.Char> _ggml_glu_op_name(int op);

ffi.Pointer<ffi.Char> ggml_glu_op_name(ggml_glu_op op) =>
    _ggml_glu_op_name(op.value);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ggml_tensor>)>()
external ffi.Pointer<ffi.Char> ggml_op_desc(ffi.Pointer<ggml_tensor> t);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_element_size(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.UnsignedInt)>(symbol: 'ggml_is_quantized')
external bool _ggml_is_quantized(int type);

bool ggml_is_quantized(ggml_type type) => _ggml_is_quantized(type.value);

@ffi.Native<ffi.UnsignedInt Function(ffi.Int)>(
  symbol: 'ggml_ftype_to_ggml_type',
)
external int _ggml_ftype_to_ggml_type(int ftype);

ggml_type ggml_ftype_to_ggml_type(ggml_ftype ftype) =>
    ggml_type.fromValue(_ggml_ftype_to_ggml_type(ftype.value));

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_transposed(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_permuted(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_empty(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_scalar(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_vector(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_matrix(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_3d(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Int Function(ffi.Pointer<ggml_tensor>)>()
external int ggml_n_dims(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous_0(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous_1(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous_2(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguously_allocated(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous_channels(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>()
external bool ggml_is_contiguous_rows(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<
  ffi.Bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external bool ggml_are_same_shape(
  ffi.Pointer<ggml_tensor> t0,
  ffi.Pointer<ggml_tensor> t1,
);

@ffi.Native<
  ffi.Bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external bool ggml_are_same_stride(
  ffi.Pointer<ggml_tensor> t0,
  ffi.Pointer<ggml_tensor> t1,
);

@ffi.Native<
  ffi.Bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external bool ggml_can_repeat(
  ffi.Pointer<ggml_tensor> t0,
  ffi.Pointer<ggml_tensor> t1,
);

@ffi.Native<ffi.Size Function()>()
external int ggml_tensor_overhead();

@ffi.Native<
  ffi.Bool Function(ffi.UnsignedInt, ffi.Pointer<ffi.Void>, ffi.Size)
>(symbol: 'ggml_validate_row_data')
external bool _ggml_validate_row_data(
  int type,
  ffi.Pointer<ffi.Void> data,
  int nbytes,
);

bool ggml_validate_row_data(
  ggml_type type,
  ffi.Pointer<ffi.Void> data,
  int nbytes,
) => _ggml_validate_row_data(type.value, data, nbytes);

@ffi.Native<ffi.Pointer<ggml_context> Function(ggml_init_params)>()
external ffi.Pointer<ggml_context> ggml_init(ggml_init_params params);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_context>)>()
external void ggml_reset(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_context>)>()
external void ggml_free(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_context>)>()
external int ggml_used_mem(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Bool Function(ffi.Pointer<ggml_context>)>()
external bool ggml_get_no_alloc(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_context>, ffi.Bool)>()
external void ggml_set_no_alloc(ffi.Pointer<ggml_context> ctx, bool no_alloc);

@ffi.Native<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_context>)>()
external ffi.Pointer<ffi.Void> ggml_get_mem_buffer(
  ffi.Pointer<ggml_context> ctx,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_context>)>()
external int ggml_get_mem_size(ffi.Pointer<ggml_context> ctx);

@ffi.Native<ffi.Size Function(ffi.Pointer<ggml_context>)>()
external int ggml_get_max_tensor_size(ffi.Pointer<ggml_context> ctx);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int,
    ffi.Pointer<ffi.Int64>,
  )
>(symbol: 'ggml_new_tensor')
external ffi.Pointer<ggml_tensor> _ggml_new_tensor(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int n_dims,
  ffi.Pointer<ffi.Int64> ne,
);

ffi.Pointer<ggml_tensor> ggml_new_tensor(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int n_dims,
  ffi.Pointer<ffi.Int64> ne,
) => _ggml_new_tensor(ctx, type.value, n_dims, ne);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int64,
  )
>(symbol: 'ggml_new_tensor_1d')
external ffi.Pointer<ggml_tensor> _ggml_new_tensor_1d(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int ne0,
);

ffi.Pointer<ggml_tensor> ggml_new_tensor_1d(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int ne0,
) => _ggml_new_tensor_1d(ctx, type.value, ne0);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int64,
    ffi.Int64,
  )
>(symbol: 'ggml_new_tensor_2d')
external ffi.Pointer<ggml_tensor> _ggml_new_tensor_2d(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int ne0,
  int ne1,
);

ffi.Pointer<ggml_tensor> ggml_new_tensor_2d(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int ne0,
  int ne1,
) => _ggml_new_tensor_2d(ctx, type.value, ne0, ne1);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>(symbol: 'ggml_new_tensor_3d')
external ffi.Pointer<ggml_tensor> _ggml_new_tensor_3d(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int ne0,
  int ne1,
  int ne2,
);

ffi.Pointer<ggml_tensor> ggml_new_tensor_3d(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int ne0,
  int ne1,
  int ne2,
) => _ggml_new_tensor_3d(ctx, type.value, ne0, ne1, ne2);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>(symbol: 'ggml_new_tensor_4d')
external ffi.Pointer<ggml_tensor> _ggml_new_tensor_4d(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
);

ffi.Pointer<ggml_tensor> ggml_new_tensor_4d(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
) => _ggml_new_tensor_4d(ctx, type.value, ne0, ne1, ne2, ne3);

@ffi.Native<
  ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_context>, ffi.Size)
>()
external ffi.Pointer<ffi.Void> ggml_new_buffer(
  ffi.Pointer<ggml_context> ctx,
  int nbytes,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_dup_tensor(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> src,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_view_tensor(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> src,
);

@ffi.Native<ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>)>()
external ffi.Pointer<ggml_tensor> ggml_get_first_tensor(
  ffi.Pointer<ggml_context> ctx,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_get_next_tensor(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_get_tensor(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Pointer<ffi.Int64>,
    ffi.Pointer<ffi.Int64>,
    ffi.Pointer<ffi.Int64>,
    ffi.Pointer<ffi.Int64>,
  )
>()
external void ggml_unravel_index(
  ffi.Pointer<ggml_tensor> tensor,
  int i,
  ffi.Pointer<ffi.Int64> i0,
  ffi.Pointer<ffi.Int64> i1,
  ffi.Pointer<ffi.Int64> i2,
  ffi.Pointer<ffi.Int64> i3,
);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<ggml_tensor>)>(
  symbol: 'ggml_get_unary_op',
)
external int _ggml_get_unary_op(ffi.Pointer<ggml_tensor> tensor);

ggml_unary_op ggml_get_unary_op(ffi.Pointer<ggml_tensor> tensor) =>
    ggml_unary_op.fromValue(_ggml_get_unary_op(tensor));

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<ggml_tensor>)>(
  symbol: 'ggml_get_glu_op',
)
external int _ggml_get_glu_op(ffi.Pointer<ggml_tensor> tensor);

ggml_glu_op ggml_get_glu_op(ffi.Pointer<ggml_tensor> tensor) =>
    ggml_glu_op.fromValue(_ggml_get_glu_op(tensor));

@ffi.Native<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_tensor>)>()
external ffi.Pointer<ffi.Void> ggml_get_data(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Pointer<ffi.Float> Function(ffi.Pointer<ggml_tensor>)>()
external ffi.Pointer<ffi.Float> ggml_get_data_f32(
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ggml_tensor>)>()
external ffi.Pointer<ffi.Char> ggml_get_name(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_name(
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_format_name(
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Char> fmt,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>)>()
external void ggml_set_input(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>)>()
external void ggml_set_output(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>)>()
external void ggml_set_param(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>)>()
external void ggml_set_loss(ffi.Pointer<ggml_tensor> tensor);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_dup(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_dup_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_add_cast')
external ffi.Pointer<ggml_tensor> _ggml_add_cast(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int type,
);

ffi.Pointer<ggml_tensor> ggml_add_cast(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ggml_type type,
) => _ggml_add_cast(ctx, a, b, type.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add_id(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> ids,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add1(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add1_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_acc(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int nb2,
  int nb3,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_acc_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int nb2,
  int nb3,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sub(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sub_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_mul(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_mul_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_div(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_div_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sqr(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sqr_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sqrt(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sqrt_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_log(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_log_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_expm1(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_expm1_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_softplus(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_softplus_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sin(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sin_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cos(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cos_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sum(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sum_rows(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cumsum(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_mean(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_argmax(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_count_equal(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_repeat(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_repeat_4d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_repeat_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_concat(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int dim,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_abs(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_abs_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sgn(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sgn_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_neg(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_neg_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_step(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_step_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_tanh(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_tanh_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_elu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_elu_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_relu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_leaky_relu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double negative_slope,
  bool inplace,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_relu_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sigmoid(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_sigmoid_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu_erf(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu_erf_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu_quick(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gelu_quick_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_silu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_silu_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_silu_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_hardswish(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_hardsigmoid(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_exp(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_exp_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_floor(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_floor_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_ceil(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_ceil_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_round(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_round_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

/// Truncates the fractional part of each element in the tensor (towards zero).
/// For example: trunc(3.7) = 3.0, trunc(-2.9) = -2.0
/// Similar to std::trunc in C/C++.
@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_trunc(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_trunc_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_xielu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double alpha_n,
  double alpha_p,
  double beta,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
    ffi.Bool,
  )
>(symbol: 'ggml_glu')
external ffi.Pointer<ggml_tensor> _ggml_glu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int op,
  bool swapped,
);

ffi.Pointer<ggml_tensor> ggml_glu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_glu_op op,
  bool swapped,
) => _ggml_glu(ctx, a, op.value, swapped);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reglu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reglu_swapped(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_swapped(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_swiglu(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_swiglu_swapped(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_erf(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_erf_swapped(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_quick(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_quick_swapped(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_glu_split')
external ffi.Pointer<ggml_tensor> _ggml_glu_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int op,
);

ffi.Pointer<ggml_tensor> ggml_glu_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ggml_glu_op op,
) => _ggml_glu_split(ctx, a, b, op.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reglu_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_swiglu_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_erf_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_geglu_quick_split(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_swiglu_oai(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  double alpha,
  double limit,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_norm(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_norm_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rms_norm(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rms_norm_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_group_norm(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_groups,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_group_norm_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_groups,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_l2_norm(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_l2_norm_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rms_norm_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  double eps,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_mul_mat(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.UnsignedInt)>(
  symbol: 'ggml_mul_mat_set_prec',
)
external void _ggml_mul_mat_set_prec(ffi.Pointer<ggml_tensor> a, int prec);

void ggml_mul_mat_set_prec(ffi.Pointer<ggml_tensor> a, ggml_prec prec) =>
    _ggml_mul_mat_set_prec(a, prec.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_mul_mat_id(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> as,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> ids,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_out_prod(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_scale(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double s,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_scale_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double s,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_scale_bias(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double s,
  double b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_scale_bias_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double s,
  double b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int nb2,
  int nb3,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int nb2,
  int nb3,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_1d_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_2d_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int nb1,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cpy(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_cast')
external ffi.Pointer<ggml_tensor> _ggml_cast(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int type,
);

ffi.Pointer<ggml_tensor> ggml_cast(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_type type,
) => _ggml_cast(ctx, a, type.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cont(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cont_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cont_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cont_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cont_4d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reshape(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reshape_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reshape_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reshape_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_reshape_4d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_view_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_view_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int nb1,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_view_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int nb1,
  int nb2,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Size,
    ffi.Size,
    ffi.Size,
    ffi.Size,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_view_4d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  int nb1,
  int nb2,
  int nb3,
  int offset,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_permute(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int axis0,
  int axis1,
  int axis2,
  int axis3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_transpose(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_get_rows(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_get_rows_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_set_rows(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_diag(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_diag_mask_inf(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_past,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_diag_mask_inf_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_past,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_diag_mask_zero(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_past,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_diag_mask_zero_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int n_past,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> mask,
  double scale,
  double max_bias,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max_ext_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> mask,
  double scale,
  double max_bias,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external void ggml_soft_max_add_sinks(
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> sinks,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max_ext_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  double scale,
  double max_bias,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_soft_max_ext_back_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  double scale,
  double max_bias,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int n_dims,
  int mode,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int n_dims,
  int mode,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_multi(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  ffi.Pointer<ffi.Int> sections,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_ext_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_multi_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  ffi.Pointer<ffi.Int> sections,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_custom(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int n_dims,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_custom_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int n_dims,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Pointer<ffi.Float>,
  )
>()
external void ggml_rope_yarn_corr_dims(
  int n_dims,
  int n_ctx_orig,
  double freq_base,
  double beta_fast,
  double beta_slow,
  ffi.Pointer<ffi.Float> dims,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_ext_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rope_multi_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  int n_dims,
  ffi.Pointer<ffi.Int> sections,
  int mode,
  int n_ctx_orig,
  double freq_base,
  double freq_scale,
  double ext_factor,
  double attn_factor,
  double beta_fast,
  double beta_slow,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_clamp(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double min,
  double max,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Bool,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_im2col')
external ffi.Pointer<ggml_tensor> _ggml_im2col(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
  bool is_2D,
  int dst_type,
);

ffi.Pointer<ggml_tensor> ggml_im2col(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
  bool is_2D,
  ggml_type dst_type,
) => _ggml_im2col(ctx, a, b, s0, s1, p0, p1, d0, d1, is_2D, dst_type.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Int64>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_im2col_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ffi.Int64> ne,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
  bool is_2D,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int p0,
  int d0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_1d_ph(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s,
  int d,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_1d_dw(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int p0,
  int d0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_1d_dw_ph(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int d0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_transpose_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int p0,
  int d0,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_im2col_3d')
external ffi.Pointer<ggml_tensor> _ggml_im2col_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int IC,
  int s0,
  int s1,
  int s2,
  int p0,
  int p1,
  int p2,
  int d0,
  int d1,
  int d2,
  int dst_type,
);

ffi.Pointer<ggml_tensor> ggml_im2col_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int IC,
  int s0,
  int s1,
  int s2,
  int p0,
  int p1,
  int p2,
  int d0,
  int d1,
  int d2,
  ggml_type dst_type,
) => _ggml_im2col_3d(
  ctx,
  a,
  b,
  IC,
  s0,
  s1,
  s2,
  p0,
  p1,
  p2,
  d0,
  d1,
  d2,
  dst_type.value,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_3d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int IC,
  int s0,
  int s1,
  int s2,
  int p0,
  int p1,
  int p2,
  int d0,
  int d1,
  int d2,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d_sk_p0(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d_s1_ph(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d_dw(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d_dw_direct(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int stride0,
  int stride1,
  int pad0,
  int pad1,
  int dilation0,
  int dilation1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_transpose_2d_p0(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int stride,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_2d_direct(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int p0,
  int p1,
  int d0,
  int d1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_conv_3d_direct(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  int s0,
  int s1,
  int s2,
  int p0,
  int p1,
  int p2,
  int d0,
  int d1,
  int d2,
  int n_channels,
  int n_batch,
  int n_channels_out,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>(symbol: 'ggml_pool_1d')
external ffi.Pointer<ggml_tensor> _ggml_pool_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int op,
  int k0,
  int s0,
  int p0,
);

ffi.Pointer<ggml_tensor> ggml_pool_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_op_pool op,
  int k0,
  int s0,
  int p0,
) => _ggml_pool_1d(ctx, a, op.value, k0, s0, p0);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
  )
>(symbol: 'ggml_pool_2d')
external ffi.Pointer<ggml_tensor> _ggml_pool_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int op,
  int k0,
  int k1,
  int s0,
  int s1,
  double p0,
  double p1,
);

ffi.Pointer<ggml_tensor> ggml_pool_2d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_op_pool op,
  int k0,
  int k1,
  int s0,
  int s1,
  double p0,
  double p1,
) => _ggml_pool_2d(ctx, a, op.value, k0, k1, s0, s1, p0, p1);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Float,
    ffi.Float,
  )
>(symbol: 'ggml_pool_2d_back')
external ffi.Pointer<ggml_tensor> _ggml_pool_2d_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> af,
  int op,
  int k0,
  int k1,
  int s0,
  int s1,
  double p0,
  double p1,
);

ffi.Pointer<ggml_tensor> ggml_pool_2d_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> af,
  ggml_op_pool op,
  int k0,
  int k1,
  int s0,
  int s1,
  double p0,
  double p1,
) => _ggml_pool_2d_back(ctx, a, af, op.value, k0, k1, s0, s1, p0, p1);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_upscale')
external ffi.Pointer<ggml_tensor> _ggml_upscale(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int scale_factor,
  int mode,
);

ffi.Pointer<ggml_tensor> ggml_upscale(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int scale_factor,
  ggml_scale_mode mode,
) => _ggml_upscale(ctx, a, scale_factor, mode.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_upscale_ext')
external ffi.Pointer<ggml_tensor> _ggml_upscale_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  int mode,
);

ffi.Pointer<ggml_tensor> ggml_upscale_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  ggml_scale_mode mode,
) => _ggml_upscale_ext(ctx, a, ne0, ne1, ne2, ne3, mode.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Uint32,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_interpolate(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  int mode,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_pad(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int p0,
  int p1,
  int p2,
  int p3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_pad_circular(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int p0,
  int p1,
  int p2,
  int p3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_pad_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int lp0,
  int rp0,
  int lp1,
  int rp1,
  int lp2,
  int rp2,
  int lp3,
  int rp3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_pad_ext_circular(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int lp0,
  int rp0,
  int lp1,
  int rp1,
  int lp2,
  int rp2,
  int lp3,
  int rp3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_pad_reflect_1d(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int p0,
  int p1,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_roll(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int shift0,
  int shift1,
  int shift2,
  int shift3,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_tri')
external ffi.Pointer<ggml_tensor> _ggml_tri(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int type,
);

ffi.Pointer<ggml_tensor> ggml_tri(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_tri_type type,
) => _ggml_tri(ctx, a, type.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_fill(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_fill_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  double c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_timestep_embedding(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> timesteps,
  int dim,
  int max_period,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_argsort')
external ffi.Pointer<ggml_tensor> _ggml_argsort(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int order,
);

ffi.Pointer<ggml_tensor> ggml_argsort(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_sort_order order,
) => _ggml_argsort(ctx, a, order.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_argsort_top_k(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int k,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_top_k(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int k,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_arange(
  ffi.Pointer<ggml_context> ctx,
  double start,
  double stop,
  double step,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
    ffi.Float,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_flash_attn_ext(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> q,
  ffi.Pointer<ggml_tensor> k,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> mask,
  double scale,
  double max_bias,
  double logit_softcap,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.UnsignedInt)>(
  symbol: 'ggml_flash_attn_ext_set_prec',
)
external void _ggml_flash_attn_ext_set_prec(
  ffi.Pointer<ggml_tensor> a,
  int prec,
);

void ggml_flash_attn_ext_set_prec(ffi.Pointer<ggml_tensor> a, ggml_prec prec) =>
    _ggml_flash_attn_ext_set_prec(a, prec.value);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<ggml_tensor>)>(
  symbol: 'ggml_flash_attn_ext_get_prec',
)
external int _ggml_flash_attn_ext_get_prec(ffi.Pointer<ggml_tensor> a);

ggml_prec ggml_flash_attn_ext_get_prec(ffi.Pointer<ggml_tensor> a) =>
    ggml_prec.fromValue(_ggml_flash_attn_ext_get_prec(a));

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external void ggml_flash_attn_ext_add_sinks(
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> sinks,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_flash_attn_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> q,
  ffi.Pointer<ggml_tensor> k,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> d,
  bool masked,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_ssm_conv(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> sx,
  ffi.Pointer<ggml_tensor> c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_ssm_scan(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> s,
  ffi.Pointer<ggml_tensor> x,
  ffi.Pointer<ggml_tensor> dt,
  ffi.Pointer<ggml_tensor> A,
  ffi.Pointer<ggml_tensor> B,
  ffi.Pointer<ggml_tensor> C,
  ffi.Pointer<ggml_tensor> ids,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_win_part(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int w,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_win_unpart(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int w0,
  int h0,
  int w,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_unary')
external ffi.Pointer<ggml_tensor> _ggml_unary(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int op,
);

ffi.Pointer<ggml_tensor> ggml_unary(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_unary_op op,
) => _ggml_unary(ctx, a, op.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.UnsignedInt,
  )
>(symbol: 'ggml_unary_inplace')
external ffi.Pointer<ggml_tensor> _ggml_unary_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int op,
);

ffi.Pointer<ggml_tensor> ggml_unary_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_unary_op op,
) => _ggml_unary_inplace(ctx, a, op.value);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_get_rel_pos(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  int qh,
  int kh,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add_rel_pos(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> pw,
  ffi.Pointer<ggml_tensor> ph,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_add_rel_pos_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> pw,
  ffi.Pointer<ggml_tensor> ph,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rwkv_wkv6(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> k,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> r,
  ffi.Pointer<ggml_tensor> tf,
  ffi.Pointer<ggml_tensor> td,
  ffi.Pointer<ggml_tensor> state,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Float,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_gated_linear_attn(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> k,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> q,
  ffi.Pointer<ggml_tensor> g,
  ffi.Pointer<ggml_tensor> state,
  double scale,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_rwkv_wkv7(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> r,
  ffi.Pointer<ggml_tensor> w,
  ffi.Pointer<ggml_tensor> k,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> state,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Bool,
    ffi.Bool,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_solve_tri(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  bool left,
  bool lower,
  bool uni,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom1_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom1(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_custom1_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom1_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom1_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ggml_custom1_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom2_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom2(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ggml_custom2_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom2_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom2_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ggml_custom2_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom3_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom3(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  ggml_custom3_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ggml_custom3_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_map_custom3_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
  ggml_custom3_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.UnsignedInt,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Pointer<ffi.Pointer<ggml_tensor>>,
    ffi.Int,
    ggml_custom_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>(symbol: 'ggml_custom_4d')
external ffi.Pointer<ggml_tensor> _ggml_custom_4d(
  ffi.Pointer<ggml_context> ctx,
  int type,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> args,
  int n_args,
  ggml_custom_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

ffi.Pointer<ggml_tensor> ggml_custom_4d(
  ffi.Pointer<ggml_context> ctx,
  ggml_type type,
  int ne0,
  int ne1,
  int ne2,
  int ne3,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> args,
  int n_args,
  ggml_custom_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
) => _ggml_custom_4d(
  ctx,
  type.value,
  ne0,
  ne1,
  ne2,
  ne3,
  args,
  n_args,
  fun,
  n_tasks,
  userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Pointer<ggml_tensor>>,
    ffi.Int,
    ggml_custom_op_t,
    ffi.Int,
    ffi.Pointer<ffi.Void>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_custom_inplace(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> args,
  int n_args,
  ggml_custom_op_t fun,
  int n_tasks,
  ffi.Pointer<ffi.Void> userdata,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss_back(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> b,
  ffi.Pointer<ggml_tensor> c,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_opt_step_adamw(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> grad,
  ffi.Pointer<ggml_tensor> m,
  ffi.Pointer<ggml_tensor> v,
  ffi.Pointer<ggml_tensor> adamw_params,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_opt_step_sgd(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_tensor> a,
  ffi.Pointer<ggml_tensor> grad,
  ffi.Pointer<ggml_tensor> sgd_params,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ffi.Pointer<ggml_tensor>>,
    ffi.Int,
    ffi.Int,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_build_forward_select(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> tensors,
  int n_tensors,
  int idx,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)
>()
external void ggml_build_forward_expand(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ffi.Pointer<ggml_tensor>>,
  )
>()
external void ggml_build_backward_expand(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> grad_accs,
);

@ffi.Native<ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>)>()
external ffi.Pointer<ggml_cgraph> ggml_new_graph(ffi.Pointer<ggml_context> ctx);

@ffi.Native<
  ffi.Pointer<ggml_cgraph> Function(
    ffi.Pointer<ggml_context>,
    ffi.Size,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_cgraph> ggml_new_graph_custom(
  ffi.Pointer<ggml_context> ctx,
  int size,
  bool grads,
);

@ffi.Native<
  ffi.Pointer<ggml_cgraph> Function(
    ffi.Pointer<ggml_context>,
    ffi.Pointer<ggml_cgraph>,
    ffi.Bool,
  )
>()
external ffi.Pointer<ggml_cgraph> ggml_graph_dup(
  ffi.Pointer<ggml_context> ctx,
  ffi.Pointer<ggml_cgraph> cgraph,
  bool force_grads,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>)
>()
external void ggml_graph_cpy(
  ffi.Pointer<ggml_cgraph> src,
  ffi.Pointer<ggml_cgraph> dst,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>()
external void ggml_graph_reset(ffi.Pointer<ggml_cgraph> cgraph);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>()
external void ggml_graph_clear(ffi.Pointer<ggml_cgraph> cgraph);

@ffi.Native<ffi.Int Function(ffi.Pointer<ggml_cgraph>)>()
external int ggml_graph_size(ffi.Pointer<ggml_cgraph> cgraph);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>, ffi.Int)
>()
external ffi.Pointer<ggml_tensor> ggml_graph_node(
  ffi.Pointer<ggml_cgraph> cgraph,
  int i,
);

@ffi.Native<
  ffi.Pointer<ffi.Pointer<ggml_tensor>> Function(ffi.Pointer<ggml_cgraph>)
>()
external ffi.Pointer<ffi.Pointer<ggml_tensor>> ggml_graph_nodes(
  ffi.Pointer<ggml_cgraph> cgraph,
);

@ffi.Native<ffi.Int Function(ffi.Pointer<ggml_cgraph>)>()
external int ggml_graph_n_nodes(ffi.Pointer<ggml_cgraph> cgraph);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)
>()
external void ggml_graph_add_node(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<ffi.Size Function()>()
external int ggml_graph_overhead();

@ffi.Native<ffi.Size Function(ffi.Size, ffi.Bool)>()
external int ggml_graph_overhead_custom(int size, bool grads);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_graph_get_tensor(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_graph_get_grad(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ggml_tensor> node,
);

@ffi.Native<
  ffi.Pointer<ggml_tensor> Function(
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external ffi.Pointer<ggml_tensor> ggml_graph_get_grad_acc(
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ggml_tensor> node,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>()
external void ggml_graph_print(ffi.Pointer<ggml_cgraph> cgraph);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ffi.Char>,
  )
>()
external void ggml_graph_dump_dot(
  ffi.Pointer<ggml_cgraph> gb,
  ffi.Pointer<ggml_cgraph> cgraph,
  ffi.Pointer<ffi.Char> filename,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_log_callback>,
    ffi.Pointer<ffi.Pointer<ffi.Void>>,
  )
>()
external void ggml_log_get(
  ffi.Pointer<ggml_log_callback> log_callback,
  ffi.Pointer<ffi.Pointer<ffi.Void>> user_data,
);

@ffi.Native<ffi.Void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>()
external void ggml_log_set(
  ggml_log_callback log_callback,
  ffi.Pointer<ffi.Void> user_data,
);

@ffi.Native<ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>)>()
external ffi.Pointer<ggml_tensor> ggml_set_zero(
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<ffi.Void Function(ffi.UnsignedInt)>(symbol: 'ggml_quantize_init')
external void _ggml_quantize_init(int type);

void ggml_quantize_init(ggml_type type) => _ggml_quantize_init(type.value);

@ffi.Native<ffi.Void Function()>()
external void ggml_quantize_free();

@ffi.Native<ffi.Bool Function(ffi.UnsignedInt)>(
  symbol: 'ggml_quantize_requires_imatrix',
)
external bool _ggml_quantize_requires_imatrix(int type);

bool ggml_quantize_requires_imatrix(ggml_type type) =>
    _ggml_quantize_requires_imatrix(type.value);

@ffi.Native<
  ffi.Size Function(
    ffi.UnsignedInt,
    ffi.Pointer<ffi.Float>,
    ffi.Pointer<ffi.Void>,
    ffi.Int64,
    ffi.Int64,
    ffi.Int64,
    ffi.Pointer<ffi.Float>,
  )
>(symbol: 'ggml_quantize_chunk')
external int _ggml_quantize_chunk(
  int type,
  ffi.Pointer<ffi.Float> src,
  ffi.Pointer<ffi.Void> dst,
  int start,
  int nrows,
  int n_per_row,
  ffi.Pointer<ffi.Float> imatrix,
);

int ggml_quantize_chunk(
  ggml_type type,
  ffi.Pointer<ffi.Float> src,
  ffi.Pointer<ffi.Void> dst,
  int start,
  int nrows,
  int n_per_row,
  ffi.Pointer<ffi.Float> imatrix,
) => _ggml_quantize_chunk(
  type.value,
  src,
  dst,
  start,
  nrows,
  n_per_row,
  imatrix,
);

@ffi.Native<ffi.Pointer<ggml_type_traits> Function(ffi.UnsignedInt)>(
  symbol: 'ggml_get_type_traits',
)
external ffi.Pointer<ggml_type_traits> _ggml_get_type_traits(int type);

ffi.Pointer<ggml_type_traits> ggml_get_type_traits(ggml_type type) =>
    _ggml_get_type_traits(type.value);

@ffi.Native<ggml_threadpool_params Function(ffi.Int)>()
external ggml_threadpool_params ggml_threadpool_params_default(int n_threads);

@ffi.Native<ffi.Void Function(ffi.Pointer<ggml_threadpool_params>, ffi.Int)>()
external void ggml_threadpool_params_init(
  ffi.Pointer<ggml_threadpool_params> p,
  int n_threads,
);

@ffi.Native<
  ffi.Bool Function(
    ffi.Pointer<ggml_threadpool_params>,
    ffi.Pointer<ggml_threadpool_params>,
  )
>()
external bool ggml_threadpool_params_match(
  ffi.Pointer<ggml_threadpool_params> p0,
  ffi.Pointer<ggml_threadpool_params> p1,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_buffer_type_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_buft_name(
  ggml_backend_buffer_type_t buft,
);

@ffi.Native<
  ggml_backend_buffer_t Function(ggml_backend_buffer_type_t, ffi.Size)
>()
external ggml_backend_buffer_t ggml_backend_buft_alloc_buffer(
  ggml_backend_buffer_type_t buft,
  int size,
);

@ffi.Native<ffi.Size Function(ggml_backend_buffer_type_t)>()
external int ggml_backend_buft_get_alignment(ggml_backend_buffer_type_t buft);

@ffi.Native<ffi.Size Function(ggml_backend_buffer_type_t)>()
external int ggml_backend_buft_get_max_size(ggml_backend_buffer_type_t buft);

@ffi.Native<
  ffi.Size Function(ggml_backend_buffer_type_t, ffi.Pointer<ggml_tensor>)
>()
external int ggml_backend_buft_get_alloc_size(
  ggml_backend_buffer_type_t buft,
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<ffi.Bool Function(ggml_backend_buffer_type_t)>()
external bool ggml_backend_buft_is_host(ggml_backend_buffer_type_t buft);

@ffi.Native<ggml_backend_dev_t Function(ggml_backend_buffer_type_t)>()
external ggml_backend_dev_t ggml_backend_buft_get_device(
  ggml_backend_buffer_type_t buft,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_buffer_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_buffer_name(
  ggml_backend_buffer_t buffer,
);

@ffi.Native<ffi.Void Function(ggml_backend_buffer_t)>()
external void ggml_backend_buffer_free(ggml_backend_buffer_t buffer);

@ffi.Native<ffi.Pointer<ffi.Void> Function(ggml_backend_buffer_t)>()
external ffi.Pointer<ffi.Void> ggml_backend_buffer_get_base(
  ggml_backend_buffer_t buffer,
);

@ffi.Native<ffi.Size Function(ggml_backend_buffer_t)>()
external int ggml_backend_buffer_get_size(ggml_backend_buffer_t buffer);

@ffi.Native<ffi.Int Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>)>(
  symbol: 'ggml_backend_buffer_init_tensor',
)
external int _ggml_backend_buffer_init_tensor(
  ggml_backend_buffer_t buffer,
  ffi.Pointer<ggml_tensor> tensor,
);

ggml_status ggml_backend_buffer_init_tensor(
  ggml_backend_buffer_t buffer,
  ffi.Pointer<ggml_tensor> tensor,
) => ggml_status.fromValue(_ggml_backend_buffer_init_tensor(buffer, tensor));

@ffi.Native<ffi.Size Function(ggml_backend_buffer_t)>()
external int ggml_backend_buffer_get_alignment(ggml_backend_buffer_t buffer);

@ffi.Native<ffi.Size Function(ggml_backend_buffer_t)>()
external int ggml_backend_buffer_get_max_size(ggml_backend_buffer_t buffer);

@ffi.Native<
  ffi.Size Function(ggml_backend_buffer_t, ffi.Pointer<ggml_tensor>)
>()
external int ggml_backend_buffer_get_alloc_size(
  ggml_backend_buffer_t buffer,
  ffi.Pointer<ggml_tensor> tensor,
);

@ffi.Native<ffi.Void Function(ggml_backend_buffer_t, ffi.Uint8)>()
external void ggml_backend_buffer_clear(
  ggml_backend_buffer_t buffer,
  int value,
);

@ffi.Native<ffi.Bool Function(ggml_backend_buffer_t)>()
external bool ggml_backend_buffer_is_host(ggml_backend_buffer_t buffer);

@ffi.Native<ffi.Void Function(ggml_backend_buffer_t, ffi.UnsignedInt)>(
  symbol: 'ggml_backend_buffer_set_usage',
)
external void _ggml_backend_buffer_set_usage(
  ggml_backend_buffer_t buffer,
  int usage,
);

void ggml_backend_buffer_set_usage(
  ggml_backend_buffer_t buffer,
  ggml_backend_buffer_usage usage,
) => _ggml_backend_buffer_set_usage(buffer, usage.value);

@ffi.Native<ffi.UnsignedInt Function(ggml_backend_buffer_t)>(
  symbol: 'ggml_backend_buffer_get_usage',
)
external int _ggml_backend_buffer_get_usage(ggml_backend_buffer_t buffer);

ggml_backend_buffer_usage ggml_backend_buffer_get_usage(
  ggml_backend_buffer_t buffer,
) =>
    ggml_backend_buffer_usage.fromValue(_ggml_backend_buffer_get_usage(buffer));

@ffi.Native<ggml_backend_buffer_type_t Function(ggml_backend_buffer_t)>()
external ggml_backend_buffer_type_t ggml_backend_buffer_get_type(
  ggml_backend_buffer_t buffer,
);

@ffi.Native<ffi.Void Function(ggml_backend_buffer_t)>()
external void ggml_backend_buffer_reset(ggml_backend_buffer_t buffer);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)
>()
external void ggml_backend_tensor_copy(
  ffi.Pointer<ggml_tensor> src,
  ffi.Pointer<ggml_tensor> dst,
);

@ffi.Native<ggml_guid_t Function(ggml_backend_t)>()
external ggml_guid_t ggml_backend_guid(ggml_backend_t backend);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_name(ggml_backend_t backend);

@ffi.Native<ffi.Void Function(ggml_backend_t)>()
external void ggml_backend_free(ggml_backend_t backend);

@ffi.Native<ggml_backend_buffer_type_t Function(ggml_backend_t)>()
external ggml_backend_buffer_type_t ggml_backend_get_default_buffer_type(
  ggml_backend_t backend,
);

@ffi.Native<ggml_backend_buffer_t Function(ggml_backend_t, ffi.Size)>()
external ggml_backend_buffer_t ggml_backend_alloc_buffer(
  ggml_backend_t backend,
  int size,
);

@ffi.Native<ffi.Size Function(ggml_backend_t)>()
external int ggml_backend_get_alignment(ggml_backend_t backend);

@ffi.Native<ffi.Size Function(ggml_backend_t)>()
external int ggml_backend_get_max_size(ggml_backend_t backend);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_t,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Size,
  )
>()
external void ggml_backend_tensor_set_async(
  ggml_backend_t backend,
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> data,
  int offset,
  int size,
);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_t,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Size,
  )
>()
external void ggml_backend_tensor_get_async(
  ggml_backend_t backend,
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> data,
  int offset,
  int size,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Size,
  )
>()
external void ggml_backend_tensor_set(
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> data,
  int offset,
  int size,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Size,
  )
>()
external void ggml_backend_tensor_get(
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> data,
  int offset,
  int size,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Uint8, ffi.Size, ffi.Size)
>()
external void ggml_backend_tensor_memset(
  ffi.Pointer<ggml_tensor> tensor,
  int value,
  int offset,
  int size,
);

@ffi.Native<ffi.Void Function(ggml_backend_t)>()
external void ggml_backend_synchronize(ggml_backend_t backend);

@ffi.Native<
  ggml_backend_graph_plan_t Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)
>()
external ggml_backend_graph_plan_t ggml_backend_graph_plan_create(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> cgraph,
);

@ffi.Native<ffi.Void Function(ggml_backend_t, ggml_backend_graph_plan_t)>()
external void ggml_backend_graph_plan_free(
  ggml_backend_t backend,
  ggml_backend_graph_plan_t plan,
);

@ffi.Native<ffi.Int Function(ggml_backend_t, ggml_backend_graph_plan_t)>(
  symbol: 'ggml_backend_graph_plan_compute',
)
external int _ggml_backend_graph_plan_compute(
  ggml_backend_t backend,
  ggml_backend_graph_plan_t plan,
);

ggml_status ggml_backend_graph_plan_compute(
  ggml_backend_t backend,
  ggml_backend_graph_plan_t plan,
) => ggml_status.fromValue(_ggml_backend_graph_plan_compute(backend, plan));

@ffi.Native<ffi.Int Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)>(
  symbol: 'ggml_backend_graph_compute',
)
external int _ggml_backend_graph_compute(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> cgraph,
);

ggml_status ggml_backend_graph_compute(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> cgraph,
) => ggml_status.fromValue(_ggml_backend_graph_compute(backend, cgraph));

@ffi.Native<ffi.Int Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)>(
  symbol: 'ggml_backend_graph_compute_async',
)
external int _ggml_backend_graph_compute_async(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> cgraph,
);

ggml_status ggml_backend_graph_compute_async(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> cgraph,
) => ggml_status.fromValue(_ggml_backend_graph_compute_async(backend, cgraph));

@ffi.Native<ffi.Bool Function(ggml_backend_t, ffi.Pointer<ggml_tensor>)>()
external bool ggml_backend_supports_op(
  ggml_backend_t backend,
  ffi.Pointer<ggml_tensor> op,
);

@ffi.Native<ffi.Bool Function(ggml_backend_t, ggml_backend_buffer_type_t)>()
external bool ggml_backend_supports_buft(
  ggml_backend_t backend,
  ggml_backend_buffer_type_t buft,
);

@ffi.Native<ffi.Bool Function(ggml_backend_t, ffi.Pointer<ggml_tensor>)>()
external bool ggml_backend_offload_op(
  ggml_backend_t backend,
  ffi.Pointer<ggml_tensor> op,
);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_t,
    ggml_backend_t,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ggml_tensor>,
  )
>()
external void ggml_backend_tensor_copy_async(
  ggml_backend_t backend_src,
  ggml_backend_t backend_dst,
  ffi.Pointer<ggml_tensor> src,
  ffi.Pointer<ggml_tensor> dst,
);

@ffi.Native<ggml_backend_dev_t Function(ggml_backend_t)>()
external ggml_backend_dev_t ggml_backend_get_device(ggml_backend_t backend);

@ffi.Native<ggml_backend_event_t Function(ggml_backend_dev_t)>()
external ggml_backend_event_t ggml_backend_event_new(ggml_backend_dev_t device);

@ffi.Native<ffi.Void Function(ggml_backend_event_t)>()
external void ggml_backend_event_free(ggml_backend_event_t event);

@ffi.Native<ffi.Void Function(ggml_backend_event_t, ggml_backend_t)>()
external void ggml_backend_event_record(
  ggml_backend_event_t event,
  ggml_backend_t backend,
);

@ffi.Native<ffi.Void Function(ggml_backend_event_t)>()
external void ggml_backend_event_synchronize(ggml_backend_event_t event);

@ffi.Native<ffi.Void Function(ggml_backend_t, ggml_backend_event_t)>()
external void ggml_backend_event_wait(
  ggml_backend_t backend,
  ggml_backend_event_t event,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_dev_name(ggml_backend_dev_t device);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_dev_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_dev_description(
  ggml_backend_dev_t device,
);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_dev_t,
    ffi.Pointer<ffi.Size>,
    ffi.Pointer<ffi.Size>,
  )
>()
external void ggml_backend_dev_memory(
  ggml_backend_dev_t device,
  ffi.Pointer<ffi.Size> free,
  ffi.Pointer<ffi.Size> total,
);

@ffi.Native<ffi.UnsignedInt Function(ggml_backend_dev_t)>(
  symbol: 'ggml_backend_dev_type',
)
external int _ggml_backend_dev_type$1(ggml_backend_dev_t device);

ggml_backend_dev_type ggml_backend_dev_type$1(ggml_backend_dev_t device) =>
    ggml_backend_dev_type.fromValue(_ggml_backend_dev_type$1(device));

@ffi.Native<
  ffi.Void Function(ggml_backend_dev_t, ffi.Pointer<ggml_backend_dev_props>)
>()
external void ggml_backend_dev_get_props(
  ggml_backend_dev_t device,
  ffi.Pointer<ggml_backend_dev_props> props,
);

@ffi.Native<ggml_backend_reg_t Function(ggml_backend_dev_t)>()
external ggml_backend_reg_t ggml_backend_dev_backend_reg(
  ggml_backend_dev_t device,
);

@ffi.Native<
  ggml_backend_t Function(ggml_backend_dev_t, ffi.Pointer<ffi.Char>)
>()
external ggml_backend_t ggml_backend_dev_init(
  ggml_backend_dev_t device,
  ffi.Pointer<ffi.Char> params,
);

@ffi.Native<ggml_backend_buffer_type_t Function(ggml_backend_dev_t)>()
external ggml_backend_buffer_type_t ggml_backend_dev_buffer_type(
  ggml_backend_dev_t device,
);

@ffi.Native<ggml_backend_buffer_type_t Function(ggml_backend_dev_t)>()
external ggml_backend_buffer_type_t ggml_backend_dev_host_buffer_type(
  ggml_backend_dev_t device,
);

@ffi.Native<
  ggml_backend_buffer_t Function(
    ggml_backend_dev_t,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Size,
  )
>()
external ggml_backend_buffer_t ggml_backend_dev_buffer_from_host_ptr(
  ggml_backend_dev_t device,
  ffi.Pointer<ffi.Void> ptr,
  int size,
  int max_tensor_size,
);

@ffi.Native<ffi.Bool Function(ggml_backend_dev_t, ffi.Pointer<ggml_tensor>)>()
external bool ggml_backend_dev_supports_op(
  ggml_backend_dev_t device,
  ffi.Pointer<ggml_tensor> op,
);

@ffi.Native<ffi.Bool Function(ggml_backend_dev_t, ggml_backend_buffer_type_t)>()
external bool ggml_backend_dev_supports_buft(
  ggml_backend_dev_t device,
  ggml_backend_buffer_type_t buft,
);

@ffi.Native<ffi.Bool Function(ggml_backend_dev_t, ffi.Pointer<ggml_tensor>)>()
external bool ggml_backend_dev_offload_op(
  ggml_backend_dev_t device,
  ffi.Pointer<ggml_tensor> op,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ggml_backend_reg_t)>()
external ffi.Pointer<ffi.Char> ggml_backend_reg_name(ggml_backend_reg_t reg);

@ffi.Native<ffi.Size Function(ggml_backend_reg_t)>()
external int ggml_backend_reg_dev_count(ggml_backend_reg_t reg);

@ffi.Native<ggml_backend_dev_t Function(ggml_backend_reg_t, ffi.Size)>()
external ggml_backend_dev_t ggml_backend_reg_dev_get(
  ggml_backend_reg_t reg,
  int index,
);

@ffi.Native<
  ffi.Pointer<ffi.Void> Function(ggml_backend_reg_t, ffi.Pointer<ffi.Char>)
>()
external ffi.Pointer<ffi.Void> ggml_backend_reg_get_proc_address(
  ggml_backend_reg_t reg,
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ffi.Void Function(ggml_backend_reg_t)>()
external void ggml_backend_register(ggml_backend_reg_t reg);

@ffi.Native<ffi.Void Function(ggml_backend_dev_t)>()
external void ggml_backend_device_register(ggml_backend_dev_t device);

@ffi.Native<ffi.Size Function()>()
external int ggml_backend_reg_count();

@ffi.Native<ggml_backend_reg_t Function(ffi.Size)>()
external ggml_backend_reg_t ggml_backend_reg_get(int index);

@ffi.Native<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>()
external ggml_backend_reg_t ggml_backend_reg_by_name(
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ffi.Size Function()>()
external int ggml_backend_dev_count();

@ffi.Native<ggml_backend_dev_t Function(ffi.Size)>()
external ggml_backend_dev_t ggml_backend_dev_get(int index);

@ffi.Native<ggml_backend_dev_t Function(ffi.Pointer<ffi.Char>)>()
external ggml_backend_dev_t ggml_backend_dev_by_name(
  ffi.Pointer<ffi.Char> name,
);

@ffi.Native<ggml_backend_dev_t Function(ffi.UnsignedInt)>(
  symbol: 'ggml_backend_dev_by_type',
)
external ggml_backend_dev_t _ggml_backend_dev_by_type(int type);

ggml_backend_dev_t ggml_backend_dev_by_type(ggml_backend_dev_type type) =>
    _ggml_backend_dev_by_type(type.value);

@ffi.Native<
  ggml_backend_t Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)
>()
external ggml_backend_t ggml_backend_init_by_name(
  ffi.Pointer<ffi.Char> name,
  ffi.Pointer<ffi.Char> params,
);

@ffi.Native<ggml_backend_t Function(ffi.UnsignedInt, ffi.Pointer<ffi.Char>)>(
  symbol: 'ggml_backend_init_by_type',
)
external ggml_backend_t _ggml_backend_init_by_type(
  int type,
  ffi.Pointer<ffi.Char> params,
);

ggml_backend_t ggml_backend_init_by_type(
  ggml_backend_dev_type type,
  ffi.Pointer<ffi.Char> params,
) => _ggml_backend_init_by_type(type.value, params);

@ffi.Native<ggml_backend_t Function()>()
external ggml_backend_t ggml_backend_init_best();

@ffi.Native<ggml_backend_reg_t Function(ffi.Pointer<ffi.Char>)>()
external ggml_backend_reg_t ggml_backend_load(ffi.Pointer<ffi.Char> path);

@ffi.Native<ffi.Void Function(ggml_backend_reg_t)>()
external void ggml_backend_unload(ggml_backend_reg_t reg);

@ffi.Native<ffi.Void Function()>()
external void ggml_backend_load_all();

@ffi.Native<ffi.Void Function(ffi.Pointer<ffi.Char>)>()
external void ggml_backend_load_all_from_path(ffi.Pointer<ffi.Char> dir_path);

@ffi.Native<
  ggml_backend_sched_t Function(
    ffi.Pointer<ggml_backend_t>,
    ffi.Pointer<ggml_backend_buffer_type_t>,
    ffi.Int,
    ffi.Size,
    ffi.Bool,
    ffi.Bool,
  )
>()
external ggml_backend_sched_t ggml_backend_sched_new(
  ffi.Pointer<ggml_backend_t> backends,
  ffi.Pointer<ggml_backend_buffer_type_t> bufts,
  int n_backends,
  int graph_size,
  bool parallel,
  bool op_offload,
);

@ffi.Native<ffi.Void Function(ggml_backend_sched_t)>()
external void ggml_backend_sched_free(ggml_backend_sched_t sched);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_sched_t,
    ffi.Pointer<ggml_cgraph>,
    ffi.Pointer<ffi.Size>,
  )
>()
external void ggml_backend_sched_reserve_size(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> measure_graph,
  ffi.Pointer<ffi.Size> sizes,
);

@ffi.Native<ffi.Bool Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>()
external bool ggml_backend_sched_reserve(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> measure_graph,
);

@ffi.Native<ffi.Int Function(ggml_backend_sched_t)>()
external int ggml_backend_sched_get_n_backends(ggml_backend_sched_t sched);

@ffi.Native<ggml_backend_t Function(ggml_backend_sched_t, ffi.Int)>()
external ggml_backend_t ggml_backend_sched_get_backend(
  ggml_backend_sched_t sched,
  int i,
);

@ffi.Native<ffi.Int Function(ggml_backend_sched_t)>()
external int ggml_backend_sched_get_n_splits(ggml_backend_sched_t sched);

@ffi.Native<ffi.Int Function(ggml_backend_sched_t)>()
external int ggml_backend_sched_get_n_copies(ggml_backend_sched_t sched);

@ffi.Native<
  ggml_backend_buffer_type_t Function(ggml_backend_sched_t, ggml_backend_t)
>()
external ggml_backend_buffer_type_t ggml_backend_sched_get_buffer_type(
  ggml_backend_sched_t sched,
  ggml_backend_t backend,
);

@ffi.Native<ffi.Size Function(ggml_backend_sched_t, ggml_backend_t)>()
external int ggml_backend_sched_get_buffer_size(
  ggml_backend_sched_t sched,
  ggml_backend_t backend,
);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_sched_t,
    ffi.Pointer<ggml_tensor>,
    ggml_backend_t,
  )
>()
external void ggml_backend_sched_set_tensor_backend(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_tensor> node,
  ggml_backend_t backend,
);

@ffi.Native<
  ggml_backend_t Function(ggml_backend_sched_t, ffi.Pointer<ggml_tensor>)
>()
external ggml_backend_t ggml_backend_sched_get_tensor_backend(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_tensor> node,
);

@ffi.Native<ffi.Void Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>()
external void ggml_backend_sched_split_graph(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
);

@ffi.Native<ffi.Bool Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>()
external bool ggml_backend_sched_alloc_graph(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
);

@ffi.Native<ffi.Int Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>(
  symbol: 'ggml_backend_sched_graph_compute',
)
external int _ggml_backend_sched_graph_compute(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
);

ggml_status ggml_backend_sched_graph_compute(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
) => ggml_status.fromValue(_ggml_backend_sched_graph_compute(sched, graph));

@ffi.Native<ffi.Int Function(ggml_backend_sched_t, ffi.Pointer<ggml_cgraph>)>(
  symbol: 'ggml_backend_sched_graph_compute_async',
)
external int _ggml_backend_sched_graph_compute_async(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
);

ggml_status ggml_backend_sched_graph_compute_async(
  ggml_backend_sched_t sched,
  ffi.Pointer<ggml_cgraph> graph,
) => ggml_status.fromValue(
  _ggml_backend_sched_graph_compute_async(sched, graph),
);

@ffi.Native<ffi.Void Function(ggml_backend_sched_t)>()
external void ggml_backend_sched_synchronize(ggml_backend_sched_t sched);

@ffi.Native<ffi.Void Function(ggml_backend_sched_t)>()
external void ggml_backend_sched_reset(ggml_backend_sched_t sched);

@ffi.Native<
  ffi.Void Function(
    ggml_backend_sched_t,
    ggml_backend_sched_eval_callback,
    ffi.Pointer<ffi.Void>,
  )
>()
external void ggml_backend_sched_set_eval_callback(
  ggml_backend_sched_t sched,
  ggml_backend_sched_eval_callback callback,
  ffi.Pointer<ffi.Void> user_data,
);

@ffi.Native<
  ggml_backend_graph_copy$1 Function(ggml_backend_t, ffi.Pointer<ggml_cgraph>)
>()
external ggml_backend_graph_copy$1 ggml_backend_graph_copy(
  ggml_backend_t backend,
  ffi.Pointer<ggml_cgraph> graph,
);

@ffi.Native<ffi.Void Function(ggml_backend_graph_copy$1)>()
external void ggml_backend_graph_copy_free(ggml_backend_graph_copy$1 copy);

@ffi.Native<
  ffi.Bool Function(
    ggml_backend_t,
    ggml_backend_t,
    ffi.Pointer<ggml_cgraph>,
    ggml_backend_eval_callback,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Pointer<ggml_tensor>>,
    ffi.Size,
  )
>()
external bool ggml_backend_compare_graph_backend(
  ggml_backend_t backend1,
  ggml_backend_t backend2,
  ffi.Pointer<ggml_cgraph> graph,
  ggml_backend_eval_callback callback,
  ffi.Pointer<ffi.Void> user_data,
  ffi.Pointer<ffi.Pointer<ggml_tensor>> test_nodes,
  int num_test_nodes,
);

@ffi.Native<
  ffi.Int Function(
    ggml_backend_buffer_t,
    ffi.Pointer<ggml_tensor>,
    ffi.Pointer<ffi.Void>,
  )
>(symbol: 'ggml_backend_tensor_alloc')
external int _ggml_backend_tensor_alloc(
  ggml_backend_buffer_t buffer,
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> addr,
);

ggml_status ggml_backend_tensor_alloc(
  ggml_backend_buffer_t buffer,
  ffi.Pointer<ggml_tensor> tensor,
  ffi.Pointer<ffi.Void> addr,
) => ggml_status.fromValue(_ggml_backend_tensor_alloc(buffer, tensor, addr));

@ffi.Native<ffi.Int Function(ffi.Pointer<ggml_tensor>)>(
  symbol: 'ggml_backend_view_init',
)
external int _ggml_backend_view_init(ffi.Pointer<ggml_tensor> tensor);

ggml_status ggml_backend_view_init(ffi.Pointer<ggml_tensor> tensor) =>
    ggml_status.fromValue(_ggml_backend_view_init(tensor));

@ffi.Native<ggml_backend_buffer_t Function(ffi.Pointer<ffi.Void>, ffi.Size)>()
external ggml_backend_buffer_t ggml_backend_cpu_buffer_from_ptr(
  ffi.Pointer<ffi.Void> ptr,
  int size,
);

@ffi.Native<ggml_backend_buffer_type_t Function()>()
external ggml_backend_buffer_type_t ggml_backend_cpu_buffer_type();

@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> mtmd_default_marker();

@ffi.Native<mtmd_context_params Function()>()
external mtmd_context_params mtmd_context_params_default();

@ffi.Native<
  ffi.Pointer<mtmd_context> Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<llama_model>,
    mtmd_context_params,
  )
>()
external ffi.Pointer<mtmd_context> mtmd_init_from_file(
  ffi.Pointer<ffi.Char> mmproj_fname,
  ffi.Pointer<llama_model> text_model,
  mtmd_context_params ctx_params,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<mtmd_context>)>()
external void mtmd_free(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<ffi.Bool Function(ffi.Pointer<mtmd_context>)>()
external bool mtmd_decode_use_non_causal(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<ffi.Bool Function(ffi.Pointer<mtmd_context>)>()
external bool mtmd_decode_use_mrope(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<ffi.Bool Function(ffi.Pointer<mtmd_context>)>()
external bool mtmd_support_vision(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<ffi.Bool Function(ffi.Pointer<mtmd_context>)>()
external bool mtmd_support_audio(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<ffi.Int Function(ffi.Pointer<mtmd_context>)>()
external int mtmd_get_audio_bitrate(ffi.Pointer<mtmd_context> ctx);

@ffi.Native<
  ffi.Pointer<mtmd_bitmap> Function(
    ffi.Uint32,
    ffi.Uint32,
    ffi.Pointer<ffi.UnsignedChar>,
  )
>()
external ffi.Pointer<mtmd_bitmap> mtmd_bitmap_init(
  int nx,
  int ny,
  ffi.Pointer<ffi.UnsignedChar> data,
);

@ffi.Native<
  ffi.Pointer<mtmd_bitmap> Function(ffi.Size, ffi.Pointer<ffi.Float>)
>()
external ffi.Pointer<mtmd_bitmap> mtmd_bitmap_init_from_audio(
  int n_samples,
  ffi.Pointer<ffi.Float> data,
);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<mtmd_bitmap>)>()
external int mtmd_bitmap_get_nx(ffi.Pointer<mtmd_bitmap> bitmap);

@ffi.Native<ffi.Uint32 Function(ffi.Pointer<mtmd_bitmap>)>()
external int mtmd_bitmap_get_ny(ffi.Pointer<mtmd_bitmap> bitmap);

@ffi.Native<ffi.Pointer<ffi.UnsignedChar> Function(ffi.Pointer<mtmd_bitmap>)>()
external ffi.Pointer<ffi.UnsignedChar> mtmd_bitmap_get_data(
  ffi.Pointer<mtmd_bitmap> bitmap,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_bitmap>)>()
external int mtmd_bitmap_get_n_bytes(ffi.Pointer<mtmd_bitmap> bitmap);

@ffi.Native<ffi.Bool Function(ffi.Pointer<mtmd_bitmap>)>()
external bool mtmd_bitmap_is_audio(ffi.Pointer<mtmd_bitmap> bitmap);

@ffi.Native<ffi.Void Function(ffi.Pointer<mtmd_bitmap>)>()
external void mtmd_bitmap_free(ffi.Pointer<mtmd_bitmap> bitmap);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<mtmd_bitmap>)>()
external ffi.Pointer<ffi.Char> mtmd_bitmap_get_id(
  ffi.Pointer<mtmd_bitmap> bitmap,
);

@ffi.Native<
  ffi.Void Function(ffi.Pointer<mtmd_bitmap>, ffi.Pointer<ffi.Char>)
>()
external void mtmd_bitmap_set_id(
  ffi.Pointer<mtmd_bitmap> bitmap,
  ffi.Pointer<ffi.Char> id,
);

@ffi.Native<ffi.Pointer<mtmd_input_chunks> Function()>()
external ffi.Pointer<mtmd_input_chunks> mtmd_input_chunks_init();

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_input_chunks>)>()
external int mtmd_input_chunks_size(ffi.Pointer<mtmd_input_chunks> chunks);

@ffi.Native<
  ffi.Pointer<mtmd_input_chunk> Function(
    ffi.Pointer<mtmd_input_chunks>,
    ffi.Size,
  )
>()
external ffi.Pointer<mtmd_input_chunk> mtmd_input_chunks_get(
  ffi.Pointer<mtmd_input_chunks> chunks,
  int idx,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<mtmd_input_chunks>)>()
external void mtmd_input_chunks_free(ffi.Pointer<mtmd_input_chunks> chunks);

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<mtmd_input_chunk>)>(
  symbol: 'mtmd_input_chunk_get_type',
)
external int _mtmd_input_chunk_get_type(ffi.Pointer<mtmd_input_chunk> chunk);

mtmd_input_chunk_type mtmd_input_chunk_get_type(
  ffi.Pointer<mtmd_input_chunk> chunk,
) => mtmd_input_chunk_type.fromValue(_mtmd_input_chunk_get_type(chunk));

@ffi.Native<
  ffi.Pointer<llama_token> Function(
    ffi.Pointer<mtmd_input_chunk>,
    ffi.Pointer<ffi.Size>,
  )
>()
external ffi.Pointer<llama_token> mtmd_input_chunk_get_tokens_text(
  ffi.Pointer<mtmd_input_chunk> chunk,
  ffi.Pointer<ffi.Size> n_tokens_output,
);

@ffi.Native<
  ffi.Pointer<mtmd_image_tokens> Function(ffi.Pointer<mtmd_input_chunk>)
>()
external ffi.Pointer<mtmd_image_tokens> mtmd_input_chunk_get_tokens_image(
  ffi.Pointer<mtmd_input_chunk> chunk,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_input_chunk>)>()
external int mtmd_input_chunk_get_n_tokens(ffi.Pointer<mtmd_input_chunk> chunk);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<mtmd_input_chunk>)>()
external ffi.Pointer<ffi.Char> mtmd_input_chunk_get_id(
  ffi.Pointer<mtmd_input_chunk> chunk,
);

@ffi.Native<llama_pos Function(ffi.Pointer<mtmd_input_chunk>)>()
external int mtmd_input_chunk_get_n_pos(ffi.Pointer<mtmd_input_chunk> chunk);

@ffi.Native<
  ffi.Pointer<mtmd_input_chunk> Function(ffi.Pointer<mtmd_input_chunk>)
>()
external ffi.Pointer<mtmd_input_chunk> mtmd_input_chunk_copy(
  ffi.Pointer<mtmd_input_chunk> chunk,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<mtmd_input_chunk>)>()
external void mtmd_input_chunk_free(ffi.Pointer<mtmd_input_chunk> chunk);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_image_tokens>)>()
external int mtmd_image_tokens_get_n_tokens(
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_image_tokens>)>()
external int mtmd_image_tokens_get_nx(
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_image_tokens>)>()
external int mtmd_image_tokens_get_ny(
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<mtmd_image_tokens>)>()
external ffi.Pointer<ffi.Char> mtmd_image_tokens_get_id(
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<llama_pos Function(ffi.Pointer<mtmd_image_tokens>)>()
external int mtmd_image_tokens_get_n_pos(
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<mtmd_input_chunks>,
    ffi.Pointer<mtmd_input_text>,
    ffi.Pointer<ffi.Pointer<mtmd_bitmap>>,
    ffi.Size,
  )
>()
external int mtmd_tokenize(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<mtmd_input_chunks> output,
  ffi.Pointer<mtmd_input_text> text,
  ffi.Pointer<ffi.Pointer<mtmd_bitmap>> bitmaps,
  int n_bitmaps,
);

@ffi.Native<
  ffi.Int32 Function(ffi.Pointer<mtmd_context>, ffi.Pointer<mtmd_image_tokens>)
>()
external int mtmd_encode(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<mtmd_image_tokens> image_tokens,
);

@ffi.Native<
  ffi.Int32 Function(ffi.Pointer<mtmd_context>, ffi.Pointer<mtmd_input_chunk>)
>()
external int mtmd_encode_chunk(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<mtmd_input_chunk> chunk,
);

@ffi.Native<ffi.Pointer<ffi.Float> Function(ffi.Pointer<mtmd_context>)>()
external ffi.Pointer<ffi.Float> mtmd_get_output_embd(
  ffi.Pointer<mtmd_context> ctx,
);

@ffi.Native<ffi.Void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>()
external void mtmd_log_set(
  ggml_log_callback log_callback,
  ffi.Pointer<ffi.Void> user_data,
);

/// //////////////////////////////////////
@ffi.Native<ffi.Pointer<mtmd_input_chunks> Function()>()
external ffi.Pointer<mtmd_input_chunks> mtmd_test_create_input_chunks();

@ffi.Native<ffi.Void Function(ggml_log_callback, ffi.Pointer<ffi.Void>)>()
external void mtmd_helper_log_set(
  ggml_log_callback log_callback,
  ffi.Pointer<ffi.Void> user_data,
);

@ffi.Native<
  ffi.Pointer<mtmd_bitmap> Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<ffi.Char>,
  )
>()
external ffi.Pointer<mtmd_bitmap> mtmd_helper_bitmap_init_from_file(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<ffi.Char> fname,
);

@ffi.Native<
  ffi.Pointer<mtmd_bitmap> Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<ffi.UnsignedChar>,
    ffi.Size,
  )
>()
external ffi.Pointer<mtmd_bitmap> mtmd_helper_bitmap_init_from_buf(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<ffi.UnsignedChar> buf,
  int len,
);

@ffi.Native<ffi.Size Function(ffi.Pointer<mtmd_input_chunks>)>()
external int mtmd_helper_get_n_tokens(ffi.Pointer<mtmd_input_chunks> chunks);

@ffi.Native<llama_pos Function(ffi.Pointer<mtmd_input_chunks>)>()
external int mtmd_helper_get_n_pos(ffi.Pointer<mtmd_input_chunks> chunks);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<llama_context>,
    ffi.Pointer<mtmd_input_chunks>,
    llama_pos,
    llama_seq_id,
    ffi.Int32,
    ffi.Bool,
    ffi.Pointer<llama_pos>,
  )
>()
external int mtmd_helper_eval_chunks(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<llama_context> lctx,
  ffi.Pointer<mtmd_input_chunks> chunks,
  int n_past,
  int seq_id,
  int n_batch,
  bool logits_last,
  ffi.Pointer<llama_pos> new_n_past,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<llama_context>,
    ffi.Pointer<mtmd_input_chunk>,
    llama_pos,
    llama_seq_id,
    ffi.Int32,
    ffi.Bool,
    ffi.Pointer<llama_pos>,
  )
>()
external int mtmd_helper_eval_chunk_single(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<llama_context> lctx,
  ffi.Pointer<mtmd_input_chunk> chunk,
  int n_past,
  int seq_id,
  int n_batch,
  bool logits_last,
  ffi.Pointer<llama_pos> new_n_past,
);

@ffi.Native<
  ffi.Int32 Function(
    ffi.Pointer<mtmd_context>,
    ffi.Pointer<llama_context>,
    ffi.Pointer<mtmd_input_chunk>,
    ffi.Pointer<ffi.Float>,
    llama_pos,
    llama_seq_id,
    ffi.Int32,
    ffi.Pointer<llama_pos>,
  )
>()
external int mtmd_helper_decode_image_chunk(
  ffi.Pointer<mtmd_context> ctx,
  ffi.Pointer<llama_context> lctx,
  ffi.Pointer<mtmd_input_chunk> chunk,
  ffi.Pointer<ffi.Float> encoded_embd,
  int n_past,
  int seq_id,
  int n_batch,
  ffi.Pointer<llama_pos> new_n_past,
);

@ffi.Native<ffi.Void Function(ffi.Int)>()
external void llama_dart_set_log_level(int level);

final class llama_vocab extends ffi.Opaque {}

final class llama_model extends ffi.Opaque {}

final class llama_context extends ffi.Opaque {}

typedef llama_token = ffi.Int32;
typedef Dartllama_token = int;

final class llama_token_data extends ffi.Struct {
  @llama_token()
  external int id;

  @ffi.Float()
  external double logit;

  @ffi.Float()
  external double p;
}

final class llama_token_data_array extends ffi.Struct {
  external ffi.Pointer<llama_token_data> data;

  @ffi.Size()
  external int size;

  @ffi.Int64()
  external int selected;

  @ffi.Bool()
  external bool sorted;
}

final class ggml_backend_buffer_type extends ffi.Opaque {}

typedef ggml_backend_buffer_type_t = ffi.Pointer<ggml_backend_buffer_type>;

final class ggml_context extends ffi.Opaque {}

final class ggml_cgraph extends ffi.Opaque {}

enum ggml_type {
  GGML_TYPE_F32(0),
  GGML_TYPE_F16(1),
  GGML_TYPE_Q4_0(2),
  GGML_TYPE_Q4_1(3),
  GGML_TYPE_Q5_0(6),
  GGML_TYPE_Q5_1(7),
  GGML_TYPE_Q8_0(8),
  GGML_TYPE_Q8_1(9),
  GGML_TYPE_Q2_K(10),
  GGML_TYPE_Q3_K(11),
  GGML_TYPE_Q4_K(12),
  GGML_TYPE_Q5_K(13),
  GGML_TYPE_Q6_K(14),
  GGML_TYPE_Q8_K(15),
  GGML_TYPE_IQ2_XXS(16),
  GGML_TYPE_IQ2_XS(17),
  GGML_TYPE_IQ3_XXS(18),
  GGML_TYPE_IQ1_S(19),
  GGML_TYPE_IQ4_NL(20),
  GGML_TYPE_IQ3_S(21),
  GGML_TYPE_IQ2_S(22),
  GGML_TYPE_IQ4_XS(23),
  GGML_TYPE_I8(24),
  GGML_TYPE_I16(25),
  GGML_TYPE_I32(26),
  GGML_TYPE_I64(27),
  GGML_TYPE_F64(28),
  GGML_TYPE_IQ1_M(29),
  GGML_TYPE_BF16(30),
  GGML_TYPE_TQ1_0(34),
  GGML_TYPE_TQ2_0(35),
  GGML_TYPE_MXFP4(39),
  GGML_TYPE_COUNT(40);

  final int value;
  const ggml_type(this.value);

  static ggml_type fromValue(int value) => switch (value) {
    0 => GGML_TYPE_F32,
    1 => GGML_TYPE_F16,
    2 => GGML_TYPE_Q4_0,
    3 => GGML_TYPE_Q4_1,
    6 => GGML_TYPE_Q5_0,
    7 => GGML_TYPE_Q5_1,
    8 => GGML_TYPE_Q8_0,
    9 => GGML_TYPE_Q8_1,
    10 => GGML_TYPE_Q2_K,
    11 => GGML_TYPE_Q3_K,
    12 => GGML_TYPE_Q4_K,
    13 => GGML_TYPE_Q5_K,
    14 => GGML_TYPE_Q6_K,
    15 => GGML_TYPE_Q8_K,
    16 => GGML_TYPE_IQ2_XXS,
    17 => GGML_TYPE_IQ2_XS,
    18 => GGML_TYPE_IQ3_XXS,
    19 => GGML_TYPE_IQ1_S,
    20 => GGML_TYPE_IQ4_NL,
    21 => GGML_TYPE_IQ3_S,
    22 => GGML_TYPE_IQ2_S,
    23 => GGML_TYPE_IQ4_XS,
    24 => GGML_TYPE_I8,
    25 => GGML_TYPE_I16,
    26 => GGML_TYPE_I32,
    27 => GGML_TYPE_I64,
    28 => GGML_TYPE_F64,
    29 => GGML_TYPE_IQ1_M,
    30 => GGML_TYPE_BF16,
    34 => GGML_TYPE_TQ1_0,
    35 => GGML_TYPE_TQ2_0,
    39 => GGML_TYPE_MXFP4,
    40 => GGML_TYPE_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_type: $value'),
  };
}

final class ggml_backend_buffer extends ffi.Opaque {}

enum ggml_op {
  GGML_OP_NONE(0),
  GGML_OP_DUP(1),
  GGML_OP_ADD(2),
  GGML_OP_ADD_ID(3),
  GGML_OP_ADD1(4),
  GGML_OP_ACC(5),
  GGML_OP_SUB(6),
  GGML_OP_MUL(7),
  GGML_OP_DIV(8),
  GGML_OP_SQR(9),
  GGML_OP_SQRT(10),
  GGML_OP_LOG(11),
  GGML_OP_SIN(12),
  GGML_OP_COS(13),
  GGML_OP_SUM(14),
  GGML_OP_SUM_ROWS(15),
  GGML_OP_CUMSUM(16),
  GGML_OP_MEAN(17),
  GGML_OP_ARGMAX(18),
  GGML_OP_COUNT_EQUAL(19),
  GGML_OP_REPEAT(20),
  GGML_OP_REPEAT_BACK(21),
  GGML_OP_CONCAT(22),
  GGML_OP_SILU_BACK(23),
  GGML_OP_NORM(24),
  GGML_OP_RMS_NORM(25),
  GGML_OP_RMS_NORM_BACK(26),
  GGML_OP_GROUP_NORM(27),
  GGML_OP_L2_NORM(28),
  GGML_OP_MUL_MAT(29),
  GGML_OP_MUL_MAT_ID(30),
  GGML_OP_OUT_PROD(31),
  GGML_OP_SCALE(32),
  GGML_OP_SET(33),
  GGML_OP_CPY(34),
  GGML_OP_CONT(35),
  GGML_OP_RESHAPE(36),
  GGML_OP_VIEW(37),
  GGML_OP_PERMUTE(38),
  GGML_OP_TRANSPOSE(39),
  GGML_OP_GET_ROWS(40),
  GGML_OP_GET_ROWS_BACK(41),
  GGML_OP_SET_ROWS(42),
  GGML_OP_DIAG(43),
  GGML_OP_DIAG_MASK_INF(44),
  GGML_OP_DIAG_MASK_ZERO(45),
  GGML_OP_SOFT_MAX(46),
  GGML_OP_SOFT_MAX_BACK(47),
  GGML_OP_ROPE(48),
  GGML_OP_ROPE_BACK(49),
  GGML_OP_CLAMP(50),
  GGML_OP_CONV_TRANSPOSE_1D(51),
  GGML_OP_IM2COL(52),
  GGML_OP_IM2COL_BACK(53),
  GGML_OP_IM2COL_3D(54),
  GGML_OP_CONV_2D(55),
  GGML_OP_CONV_3D(56),
  GGML_OP_CONV_2D_DW(57),
  GGML_OP_CONV_TRANSPOSE_2D(58),
  GGML_OP_POOL_1D(59),
  GGML_OP_POOL_2D(60),
  GGML_OP_POOL_2D_BACK(61),
  GGML_OP_UPSCALE(62),
  GGML_OP_PAD(63),
  GGML_OP_PAD_REFLECT_1D(64),
  GGML_OP_ROLL(65),
  GGML_OP_ARANGE(66),
  GGML_OP_TIMESTEP_EMBEDDING(67),
  GGML_OP_ARGSORT(68),
  GGML_OP_TOP_K(69),
  GGML_OP_LEAKY_RELU(70),
  GGML_OP_TRI(71),
  GGML_OP_FILL(72),
  GGML_OP_FLASH_ATTN_EXT(73),
  GGML_OP_FLASH_ATTN_BACK(74),
  GGML_OP_SSM_CONV(75),
  GGML_OP_SSM_SCAN(76),
  GGML_OP_WIN_PART(77),
  GGML_OP_WIN_UNPART(78),
  GGML_OP_GET_REL_POS(79),
  GGML_OP_ADD_REL_POS(80),
  GGML_OP_RWKV_WKV6(81),
  GGML_OP_GATED_LINEAR_ATTN(82),
  GGML_OP_RWKV_WKV7(83),
  GGML_OP_SOLVE_TRI(84),
  GGML_OP_UNARY(85),
  GGML_OP_MAP_CUSTOM1(86),
  GGML_OP_MAP_CUSTOM2(87),
  GGML_OP_MAP_CUSTOM3(88),
  GGML_OP_CUSTOM(89),
  GGML_OP_CROSS_ENTROPY_LOSS(90),
  GGML_OP_CROSS_ENTROPY_LOSS_BACK(91),
  GGML_OP_OPT_STEP_ADAMW(92),
  GGML_OP_OPT_STEP_SGD(93),
  GGML_OP_GLU(94),
  GGML_OP_COUNT(95);

  final int value;
  const ggml_op(this.value);

  static ggml_op fromValue(int value) => switch (value) {
    0 => GGML_OP_NONE,
    1 => GGML_OP_DUP,
    2 => GGML_OP_ADD,
    3 => GGML_OP_ADD_ID,
    4 => GGML_OP_ADD1,
    5 => GGML_OP_ACC,
    6 => GGML_OP_SUB,
    7 => GGML_OP_MUL,
    8 => GGML_OP_DIV,
    9 => GGML_OP_SQR,
    10 => GGML_OP_SQRT,
    11 => GGML_OP_LOG,
    12 => GGML_OP_SIN,
    13 => GGML_OP_COS,
    14 => GGML_OP_SUM,
    15 => GGML_OP_SUM_ROWS,
    16 => GGML_OP_CUMSUM,
    17 => GGML_OP_MEAN,
    18 => GGML_OP_ARGMAX,
    19 => GGML_OP_COUNT_EQUAL,
    20 => GGML_OP_REPEAT,
    21 => GGML_OP_REPEAT_BACK,
    22 => GGML_OP_CONCAT,
    23 => GGML_OP_SILU_BACK,
    24 => GGML_OP_NORM,
    25 => GGML_OP_RMS_NORM,
    26 => GGML_OP_RMS_NORM_BACK,
    27 => GGML_OP_GROUP_NORM,
    28 => GGML_OP_L2_NORM,
    29 => GGML_OP_MUL_MAT,
    30 => GGML_OP_MUL_MAT_ID,
    31 => GGML_OP_OUT_PROD,
    32 => GGML_OP_SCALE,
    33 => GGML_OP_SET,
    34 => GGML_OP_CPY,
    35 => GGML_OP_CONT,
    36 => GGML_OP_RESHAPE,
    37 => GGML_OP_VIEW,
    38 => GGML_OP_PERMUTE,
    39 => GGML_OP_TRANSPOSE,
    40 => GGML_OP_GET_ROWS,
    41 => GGML_OP_GET_ROWS_BACK,
    42 => GGML_OP_SET_ROWS,
    43 => GGML_OP_DIAG,
    44 => GGML_OP_DIAG_MASK_INF,
    45 => GGML_OP_DIAG_MASK_ZERO,
    46 => GGML_OP_SOFT_MAX,
    47 => GGML_OP_SOFT_MAX_BACK,
    48 => GGML_OP_ROPE,
    49 => GGML_OP_ROPE_BACK,
    50 => GGML_OP_CLAMP,
    51 => GGML_OP_CONV_TRANSPOSE_1D,
    52 => GGML_OP_IM2COL,
    53 => GGML_OP_IM2COL_BACK,
    54 => GGML_OP_IM2COL_3D,
    55 => GGML_OP_CONV_2D,
    56 => GGML_OP_CONV_3D,
    57 => GGML_OP_CONV_2D_DW,
    58 => GGML_OP_CONV_TRANSPOSE_2D,
    59 => GGML_OP_POOL_1D,
    60 => GGML_OP_POOL_2D,
    61 => GGML_OP_POOL_2D_BACK,
    62 => GGML_OP_UPSCALE,
    63 => GGML_OP_PAD,
    64 => GGML_OP_PAD_REFLECT_1D,
    65 => GGML_OP_ROLL,
    66 => GGML_OP_ARANGE,
    67 => GGML_OP_TIMESTEP_EMBEDDING,
    68 => GGML_OP_ARGSORT,
    69 => GGML_OP_TOP_K,
    70 => GGML_OP_LEAKY_RELU,
    71 => GGML_OP_TRI,
    72 => GGML_OP_FILL,
    73 => GGML_OP_FLASH_ATTN_EXT,
    74 => GGML_OP_FLASH_ATTN_BACK,
    75 => GGML_OP_SSM_CONV,
    76 => GGML_OP_SSM_SCAN,
    77 => GGML_OP_WIN_PART,
    78 => GGML_OP_WIN_UNPART,
    79 => GGML_OP_GET_REL_POS,
    80 => GGML_OP_ADD_REL_POS,
    81 => GGML_OP_RWKV_WKV6,
    82 => GGML_OP_GATED_LINEAR_ATTN,
    83 => GGML_OP_RWKV_WKV7,
    84 => GGML_OP_SOLVE_TRI,
    85 => GGML_OP_UNARY,
    86 => GGML_OP_MAP_CUSTOM1,
    87 => GGML_OP_MAP_CUSTOM2,
    88 => GGML_OP_MAP_CUSTOM3,
    89 => GGML_OP_CUSTOM,
    90 => GGML_OP_CROSS_ENTROPY_LOSS,
    91 => GGML_OP_CROSS_ENTROPY_LOSS_BACK,
    92 => GGML_OP_OPT_STEP_ADAMW,
    93 => GGML_OP_OPT_STEP_SGD,
    94 => GGML_OP_GLU,
    95 => GGML_OP_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_op: $value'),
  };
}

final class ggml_tensor extends ffi.Struct {
  @ffi.UnsignedInt()
  external int typeAsInt;

  ggml_type get type => ggml_type.fromValue(typeAsInt);

  external ffi.Pointer<ggml_backend_buffer> buffer;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> ne;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Size> nb;

  @ffi.UnsignedInt()
  external int opAsInt;

  ggml_op get op => ggml_op.fromValue(opAsInt);

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int32> op_params;

  @ffi.Int32()
  external int flags;

  @ffi.Array.multi([10])
  external ffi.Array<ffi.Pointer<ggml_tensor>> src;

  external ffi.Pointer<ggml_tensor> view_src;

  @ffi.Size()
  external int view_offs;

  external ffi.Pointer<ffi.Void> data;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> name;

  external ffi.Pointer<ffi.Void> extra;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> padding;
}

final class llama_sampler_data extends ffi.Struct {
  external ffi.Pointer<ggml_tensor> logits;

  external ffi.Pointer<ggml_tensor> probs;

  external ffi.Pointer<ggml_tensor> sampled;

  external ffi.Pointer<ggml_tensor> candidates;
}

final class llama_sampler_i extends ffi.Struct {
  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_sampler> smpl)
    >
  >
  name;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(ffi.Pointer<llama_sampler> smpl, llama_token token)
    >
  >
  accept;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<llama_sampler> smpl,
        ffi.Pointer<llama_token_data_array> cur_p,
      )
    >
  >
  apply;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler> smpl)>
  >
  reset;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Pointer<llama_sampler> Function(ffi.Pointer<llama_sampler> smpl)
    >
  >
  clone;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler> smpl)>
  >
  free;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Bool Function(
        ffi.Pointer<llama_sampler> smpl,
        ggml_backend_buffer_type_t buft,
      )
    >
  >
  backend_init;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<llama_sampler> smpl,
        ffi.Pointer<ggml_context> ctx,
        ffi.Pointer<ggml_cgraph> gf,
        ffi.Pointer<ggml_tensor> selected_token,
      )
    >
  >
  backend_accept;

  external ffi.Pointer<
    ffi.NativeFunction<
      ffi.Void Function(
        ffi.Pointer<llama_sampler> smpl,
        ffi.Pointer<ggml_context> ctx,
        ffi.Pointer<ggml_cgraph> gf,
        ffi.Pointer<llama_sampler_data> data,
      )
    >
  >
  backend_apply;

  external ffi.Pointer<
    ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_sampler> smpl)>
  >
  backend_set_input;
}

typedef llama_sampler_context_t = ffi.Pointer<ffi.Void>;

final class llama_sampler extends ffi.Struct {
  external ffi.Pointer<llama_sampler_i> iface;

  external llama_sampler_context_t ctx;
}

final class llama_memory_i extends ffi.Opaque {}

typedef llama_memory_t = ffi.Pointer<llama_memory_i>;
typedef llama_pos = ffi.Int32;
typedef Dartllama_pos = int;
typedef llama_seq_id = ffi.Int32;
typedef Dartllama_seq_id = int;

enum llama_vocab_type {
  LLAMA_VOCAB_TYPE_NONE(0),
  LLAMA_VOCAB_TYPE_SPM(1),
  LLAMA_VOCAB_TYPE_BPE(2),
  LLAMA_VOCAB_TYPE_WPM(3),
  LLAMA_VOCAB_TYPE_UGM(4),
  LLAMA_VOCAB_TYPE_RWKV(5),
  LLAMA_VOCAB_TYPE_PLAMO2(6);

  final int value;
  const llama_vocab_type(this.value);

  static llama_vocab_type fromValue(int value) => switch (value) {
    0 => LLAMA_VOCAB_TYPE_NONE,
    1 => LLAMA_VOCAB_TYPE_SPM,
    2 => LLAMA_VOCAB_TYPE_BPE,
    3 => LLAMA_VOCAB_TYPE_WPM,
    4 => LLAMA_VOCAB_TYPE_UGM,
    5 => LLAMA_VOCAB_TYPE_RWKV,
    6 => LLAMA_VOCAB_TYPE_PLAMO2,
    _ => throw ArgumentError('Unknown value for llama_vocab_type: $value'),
  };
}

enum llama_rope_type {
  LLAMA_ROPE_TYPE_NONE(-1),
  LLAMA_ROPE_TYPE_NORM(0),
  LLAMA_ROPE_TYPE_NEOX(2),
  LLAMA_ROPE_TYPE_MROPE(8),
  LLAMA_ROPE_TYPE_IMROPE(40),
  LLAMA_ROPE_TYPE_VISION(24);

  final int value;
  const llama_rope_type(this.value);

  static llama_rope_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ROPE_TYPE_NONE,
    0 => LLAMA_ROPE_TYPE_NORM,
    2 => LLAMA_ROPE_TYPE_NEOX,
    8 => LLAMA_ROPE_TYPE_MROPE,
    40 => LLAMA_ROPE_TYPE_IMROPE,
    24 => LLAMA_ROPE_TYPE_VISION,
    _ => throw ArgumentError('Unknown value for llama_rope_type: $value'),
  };
}

enum llama_token_type {
  LLAMA_TOKEN_TYPE_UNDEFINED(0),
  LLAMA_TOKEN_TYPE_NORMAL(1),
  LLAMA_TOKEN_TYPE_UNKNOWN(2),
  LLAMA_TOKEN_TYPE_CONTROL(3),
  LLAMA_TOKEN_TYPE_USER_DEFINED(4),
  LLAMA_TOKEN_TYPE_UNUSED(5),
  LLAMA_TOKEN_TYPE_BYTE(6);

  final int value;
  const llama_token_type(this.value);

  static llama_token_type fromValue(int value) => switch (value) {
    0 => LLAMA_TOKEN_TYPE_UNDEFINED,
    1 => LLAMA_TOKEN_TYPE_NORMAL,
    2 => LLAMA_TOKEN_TYPE_UNKNOWN,
    3 => LLAMA_TOKEN_TYPE_CONTROL,
    4 => LLAMA_TOKEN_TYPE_USER_DEFINED,
    5 => LLAMA_TOKEN_TYPE_UNUSED,
    6 => LLAMA_TOKEN_TYPE_BYTE,
    _ => throw ArgumentError('Unknown value for llama_token_type: $value'),
  };
}

enum llama_token_attr {
  LLAMA_TOKEN_ATTR_UNDEFINED(0),
  LLAMA_TOKEN_ATTR_UNKNOWN(1),
  LLAMA_TOKEN_ATTR_UNUSED(2),
  LLAMA_TOKEN_ATTR_NORMAL(4),
  LLAMA_TOKEN_ATTR_CONTROL(8),
  LLAMA_TOKEN_ATTR_USER_DEFINED(16),
  LLAMA_TOKEN_ATTR_BYTE(32),
  LLAMA_TOKEN_ATTR_NORMALIZED(64),
  LLAMA_TOKEN_ATTR_LSTRIP(128),
  LLAMA_TOKEN_ATTR_RSTRIP(256),
  LLAMA_TOKEN_ATTR_SINGLE_WORD(512);

  final int value;
  const llama_token_attr(this.value);

  static llama_token_attr fromValue(int value) => switch (value) {
    0 => LLAMA_TOKEN_ATTR_UNDEFINED,
    1 => LLAMA_TOKEN_ATTR_UNKNOWN,
    2 => LLAMA_TOKEN_ATTR_UNUSED,
    4 => LLAMA_TOKEN_ATTR_NORMAL,
    8 => LLAMA_TOKEN_ATTR_CONTROL,
    16 => LLAMA_TOKEN_ATTR_USER_DEFINED,
    32 => LLAMA_TOKEN_ATTR_BYTE,
    64 => LLAMA_TOKEN_ATTR_NORMALIZED,
    128 => LLAMA_TOKEN_ATTR_LSTRIP,
    256 => LLAMA_TOKEN_ATTR_RSTRIP,
    512 => LLAMA_TOKEN_ATTR_SINGLE_WORD,
    _ => throw ArgumentError('Unknown value for llama_token_attr: $value'),
  };
}

enum llama_ftype {
  LLAMA_FTYPE_ALL_F32(0),
  LLAMA_FTYPE_MOSTLY_F16(1),
  LLAMA_FTYPE_MOSTLY_Q4_0(2),
  LLAMA_FTYPE_MOSTLY_Q4_1(3),
  LLAMA_FTYPE_MOSTLY_Q8_0(7),
  LLAMA_FTYPE_MOSTLY_Q5_0(8),
  LLAMA_FTYPE_MOSTLY_Q5_1(9),
  LLAMA_FTYPE_MOSTLY_Q2_K(10),
  LLAMA_FTYPE_MOSTLY_Q3_K_S(11),
  LLAMA_FTYPE_MOSTLY_Q3_K_M(12),
  LLAMA_FTYPE_MOSTLY_Q3_K_L(13),
  LLAMA_FTYPE_MOSTLY_Q4_K_S(14),
  LLAMA_FTYPE_MOSTLY_Q4_K_M(15),
  LLAMA_FTYPE_MOSTLY_Q5_K_S(16),
  LLAMA_FTYPE_MOSTLY_Q5_K_M(17),
  LLAMA_FTYPE_MOSTLY_Q6_K(18),
  LLAMA_FTYPE_MOSTLY_IQ2_XXS(19),
  LLAMA_FTYPE_MOSTLY_IQ2_XS(20),
  LLAMA_FTYPE_MOSTLY_Q2_K_S(21),
  LLAMA_FTYPE_MOSTLY_IQ3_XS(22),
  LLAMA_FTYPE_MOSTLY_IQ3_XXS(23),
  LLAMA_FTYPE_MOSTLY_IQ1_S(24),
  LLAMA_FTYPE_MOSTLY_IQ4_NL(25),
  LLAMA_FTYPE_MOSTLY_IQ3_S(26),
  LLAMA_FTYPE_MOSTLY_IQ3_M(27),
  LLAMA_FTYPE_MOSTLY_IQ2_S(28),
  LLAMA_FTYPE_MOSTLY_IQ2_M(29),
  LLAMA_FTYPE_MOSTLY_IQ4_XS(30),
  LLAMA_FTYPE_MOSTLY_IQ1_M(31),
  LLAMA_FTYPE_MOSTLY_BF16(32),
  LLAMA_FTYPE_MOSTLY_TQ1_0(36),
  LLAMA_FTYPE_MOSTLY_TQ2_0(37),
  LLAMA_FTYPE_MOSTLY_MXFP4_MOE(38),
  LLAMA_FTYPE_GUESSED(1024);

  final int value;
  const llama_ftype(this.value);

  static llama_ftype fromValue(int value) => switch (value) {
    0 => LLAMA_FTYPE_ALL_F32,
    1 => LLAMA_FTYPE_MOSTLY_F16,
    2 => LLAMA_FTYPE_MOSTLY_Q4_0,
    3 => LLAMA_FTYPE_MOSTLY_Q4_1,
    7 => LLAMA_FTYPE_MOSTLY_Q8_0,
    8 => LLAMA_FTYPE_MOSTLY_Q5_0,
    9 => LLAMA_FTYPE_MOSTLY_Q5_1,
    10 => LLAMA_FTYPE_MOSTLY_Q2_K,
    11 => LLAMA_FTYPE_MOSTLY_Q3_K_S,
    12 => LLAMA_FTYPE_MOSTLY_Q3_K_M,
    13 => LLAMA_FTYPE_MOSTLY_Q3_K_L,
    14 => LLAMA_FTYPE_MOSTLY_Q4_K_S,
    15 => LLAMA_FTYPE_MOSTLY_Q4_K_M,
    16 => LLAMA_FTYPE_MOSTLY_Q5_K_S,
    17 => LLAMA_FTYPE_MOSTLY_Q5_K_M,
    18 => LLAMA_FTYPE_MOSTLY_Q6_K,
    19 => LLAMA_FTYPE_MOSTLY_IQ2_XXS,
    20 => LLAMA_FTYPE_MOSTLY_IQ2_XS,
    21 => LLAMA_FTYPE_MOSTLY_Q2_K_S,
    22 => LLAMA_FTYPE_MOSTLY_IQ3_XS,
    23 => LLAMA_FTYPE_MOSTLY_IQ3_XXS,
    24 => LLAMA_FTYPE_MOSTLY_IQ1_S,
    25 => LLAMA_FTYPE_MOSTLY_IQ4_NL,
    26 => LLAMA_FTYPE_MOSTLY_IQ3_S,
    27 => LLAMA_FTYPE_MOSTLY_IQ3_M,
    28 => LLAMA_FTYPE_MOSTLY_IQ2_S,
    29 => LLAMA_FTYPE_MOSTLY_IQ2_M,
    30 => LLAMA_FTYPE_MOSTLY_IQ4_XS,
    31 => LLAMA_FTYPE_MOSTLY_IQ1_M,
    32 => LLAMA_FTYPE_MOSTLY_BF16,
    36 => LLAMA_FTYPE_MOSTLY_TQ1_0,
    37 => LLAMA_FTYPE_MOSTLY_TQ2_0,
    38 => LLAMA_FTYPE_MOSTLY_MXFP4_MOE,
    1024 => LLAMA_FTYPE_GUESSED,
    _ => throw ArgumentError('Unknown value for llama_ftype: $value'),
  };
}

enum llama_rope_scaling_type {
  LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED(-1),
  LLAMA_ROPE_SCALING_TYPE_NONE(0),
  LLAMA_ROPE_SCALING_TYPE_LINEAR(1),
  LLAMA_ROPE_SCALING_TYPE_YARN(2),
  LLAMA_ROPE_SCALING_TYPE_LONGROPE(3);

  static const LLAMA_ROPE_SCALING_TYPE_MAX_VALUE =
      LLAMA_ROPE_SCALING_TYPE_LONGROPE;

  final int value;
  const llama_rope_scaling_type(this.value);

  static llama_rope_scaling_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ROPE_SCALING_TYPE_UNSPECIFIED,
    0 => LLAMA_ROPE_SCALING_TYPE_NONE,
    1 => LLAMA_ROPE_SCALING_TYPE_LINEAR,
    2 => LLAMA_ROPE_SCALING_TYPE_YARN,
    3 => LLAMA_ROPE_SCALING_TYPE_LONGROPE,
    _ => throw ArgumentError(
      'Unknown value for llama_rope_scaling_type: $value',
    ),
  };

  @override
  String toString() {
    if (this == LLAMA_ROPE_SCALING_TYPE_LONGROPE)
      return "llama_rope_scaling_type.LLAMA_ROPE_SCALING_TYPE_LONGROPE, llama_rope_scaling_type.LLAMA_ROPE_SCALING_TYPE_MAX_VALUE";
    return super.toString();
  }
}

enum llama_pooling_type {
  LLAMA_POOLING_TYPE_UNSPECIFIED(-1),
  LLAMA_POOLING_TYPE_NONE(0),
  LLAMA_POOLING_TYPE_MEAN(1),
  LLAMA_POOLING_TYPE_CLS(2),
  LLAMA_POOLING_TYPE_LAST(3),
  LLAMA_POOLING_TYPE_RANK(4);

  final int value;
  const llama_pooling_type(this.value);

  static llama_pooling_type fromValue(int value) => switch (value) {
    -1 => LLAMA_POOLING_TYPE_UNSPECIFIED,
    0 => LLAMA_POOLING_TYPE_NONE,
    1 => LLAMA_POOLING_TYPE_MEAN,
    2 => LLAMA_POOLING_TYPE_CLS,
    3 => LLAMA_POOLING_TYPE_LAST,
    4 => LLAMA_POOLING_TYPE_RANK,
    _ => throw ArgumentError('Unknown value for llama_pooling_type: $value'),
  };
}

enum llama_attention_type {
  LLAMA_ATTENTION_TYPE_UNSPECIFIED(-1),
  LLAMA_ATTENTION_TYPE_CAUSAL(0),
  LLAMA_ATTENTION_TYPE_NON_CAUSAL(1);

  final int value;
  const llama_attention_type(this.value);

  static llama_attention_type fromValue(int value) => switch (value) {
    -1 => LLAMA_ATTENTION_TYPE_UNSPECIFIED,
    0 => LLAMA_ATTENTION_TYPE_CAUSAL,
    1 => LLAMA_ATTENTION_TYPE_NON_CAUSAL,
    _ => throw ArgumentError('Unknown value for llama_attention_type: $value'),
  };
}

enum llama_flash_attn_type {
  LLAMA_FLASH_ATTN_TYPE_AUTO(-1),
  LLAMA_FLASH_ATTN_TYPE_DISABLED(0),
  LLAMA_FLASH_ATTN_TYPE_ENABLED(1);

  final int value;
  const llama_flash_attn_type(this.value);

  static llama_flash_attn_type fromValue(int value) => switch (value) {
    -1 => LLAMA_FLASH_ATTN_TYPE_AUTO,
    0 => LLAMA_FLASH_ATTN_TYPE_DISABLED,
    1 => LLAMA_FLASH_ATTN_TYPE_ENABLED,
    _ => throw ArgumentError('Unknown value for llama_flash_attn_type: $value'),
  };
}

enum llama_split_mode {
  LLAMA_SPLIT_MODE_NONE(0),
  LLAMA_SPLIT_MODE_LAYER(1),
  LLAMA_SPLIT_MODE_ROW(2);

  final int value;
  const llama_split_mode(this.value);

  static llama_split_mode fromValue(int value) => switch (value) {
    0 => LLAMA_SPLIT_MODE_NONE,
    1 => LLAMA_SPLIT_MODE_LAYER,
    2 => LLAMA_SPLIT_MODE_ROW,
    _ => throw ArgumentError('Unknown value for llama_split_mode: $value'),
  };
}

typedef llama_progress_callbackFunction =
    ffi.Bool Function(ffi.Float progress, ffi.Pointer<ffi.Void> user_data);
typedef Dartllama_progress_callbackFunction =
    bool Function(double progress, ffi.Pointer<ffi.Void> user_data);
typedef llama_progress_callback =
    ffi.Pointer<ffi.NativeFunction<llama_progress_callbackFunction>>;

final class llama_batch extends ffi.Struct {
  @ffi.Int32()
  external int n_tokens;

  external ffi.Pointer<llama_token> token;

  external ffi.Pointer<ffi.Float> embd;

  external ffi.Pointer<llama_pos> pos;

  external ffi.Pointer<ffi.Int32> n_seq_id;

  external ffi.Pointer<ffi.Pointer<llama_seq_id>> seq_id;

  external ffi.Pointer<ffi.Int8> logits;
}

enum llama_model_kv_override_type {
  LLAMA_KV_OVERRIDE_TYPE_INT(0),
  LLAMA_KV_OVERRIDE_TYPE_FLOAT(1),
  LLAMA_KV_OVERRIDE_TYPE_BOOL(2),
  LLAMA_KV_OVERRIDE_TYPE_STR(3);

  final int value;
  const llama_model_kv_override_type(this.value);

  static llama_model_kv_override_type fromValue(int value) => switch (value) {
    0 => LLAMA_KV_OVERRIDE_TYPE_INT,
    1 => LLAMA_KV_OVERRIDE_TYPE_FLOAT,
    2 => LLAMA_KV_OVERRIDE_TYPE_BOOL,
    3 => LLAMA_KV_OVERRIDE_TYPE_STR,
    _ => throw ArgumentError(
      'Unknown value for llama_model_kv_override_type: $value',
    ),
  };
}

enum llama_model_meta_key {
  LLAMA_MODEL_META_KEY_SAMPLING_SEQUENCE(0),
  LLAMA_MODEL_META_KEY_SAMPLING_TOP_K(1),
  LLAMA_MODEL_META_KEY_SAMPLING_TOP_P(2),
  LLAMA_MODEL_META_KEY_SAMPLING_MIN_P(3),
  LLAMA_MODEL_META_KEY_SAMPLING_XTC_PROBABILITY(4),
  LLAMA_MODEL_META_KEY_SAMPLING_XTC_THRESHOLD(5),
  LLAMA_MODEL_META_KEY_SAMPLING_TEMP(6),
  LLAMA_MODEL_META_KEY_SAMPLING_PENALTY_LAST_N(7),
  LLAMA_MODEL_META_KEY_SAMPLING_PENALTY_REPEAT(8),
  LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT(9),
  LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT_TAU(10),
  LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT_ETA(11);

  final int value;
  const llama_model_meta_key(this.value);

  static llama_model_meta_key fromValue(int value) => switch (value) {
    0 => LLAMA_MODEL_META_KEY_SAMPLING_SEQUENCE,
    1 => LLAMA_MODEL_META_KEY_SAMPLING_TOP_K,
    2 => LLAMA_MODEL_META_KEY_SAMPLING_TOP_P,
    3 => LLAMA_MODEL_META_KEY_SAMPLING_MIN_P,
    4 => LLAMA_MODEL_META_KEY_SAMPLING_XTC_PROBABILITY,
    5 => LLAMA_MODEL_META_KEY_SAMPLING_XTC_THRESHOLD,
    6 => LLAMA_MODEL_META_KEY_SAMPLING_TEMP,
    7 => LLAMA_MODEL_META_KEY_SAMPLING_PENALTY_LAST_N,
    8 => LLAMA_MODEL_META_KEY_SAMPLING_PENALTY_REPEAT,
    9 => LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT,
    10 => LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT_TAU,
    11 => LLAMA_MODEL_META_KEY_SAMPLING_MIROSTAT_ETA,
    _ => throw ArgumentError('Unknown value for llama_model_meta_key: $value'),
  };
}

final class UnnamedUnion extends ffi.Union {
  @ffi.Int64()
  external int val_i64;

  @ffi.Double()
  external double val_f64;

  @ffi.Bool()
  external bool val_bool;

  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> val_str;
}

final class llama_model_kv_override extends ffi.Struct {
  @ffi.UnsignedInt()
  external int tagAsInt;

  llama_model_kv_override_type get tag =>
      llama_model_kv_override_type.fromValue(tagAsInt);

  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> key;

  external UnnamedUnion unnamed;
}

final class llama_model_tensor_buft_override extends ffi.Struct {
  external ffi.Pointer<ffi.Char> pattern;

  external ggml_backend_buffer_type_t buft;
}

final class ggml_backend_device extends ffi.Opaque {}

typedef ggml_backend_dev_t = ffi.Pointer<ggml_backend_device>;

final class llama_model_params extends ffi.Struct {
  external ffi.Pointer<ggml_backend_dev_t> devices;

  external ffi.Pointer<llama_model_tensor_buft_override> tensor_buft_overrides;

  @ffi.Int32()
  external int n_gpu_layers;

  @ffi.UnsignedInt()
  external int split_modeAsInt;

  llama_split_mode get split_mode =>
      llama_split_mode.fromValue(split_modeAsInt);

  @ffi.Int32()
  external int main_gpu;

  external ffi.Pointer<ffi.Float> tensor_split;

  external llama_progress_callback progress_callback;

  external ffi.Pointer<ffi.Void> progress_callback_user_data;

  external ffi.Pointer<llama_model_kv_override> kv_overrides;

  @ffi.Bool()
  external bool vocab_only;

  @ffi.Bool()
  external bool use_mmap;

  @ffi.Bool()
  external bool use_direct_io;

  @ffi.Bool()
  external bool use_mlock;

  @ffi.Bool()
  external bool check_tensors;

  @ffi.Bool()
  external bool use_extra_bufts;

  @ffi.Bool()
  external bool no_host;

  @ffi.Bool()
  external bool no_alloc;
}

final class llama_sampler_seq_config extends ffi.Struct {
  @llama_seq_id()
  external int seq_id;

  external ffi.Pointer<llama_sampler> sampler;
}

typedef ggml_backend_sched_eval_callbackFunction =
    ffi.Bool Function(
      ffi.Pointer<ggml_tensor> t,
      ffi.Bool ask,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef Dartggml_backend_sched_eval_callbackFunction =
    bool Function(
      ffi.Pointer<ggml_tensor> t,
      bool ask,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef ggml_backend_sched_eval_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_sched_eval_callbackFunction>>;
typedef ggml_abort_callbackFunction =
    ffi.Bool Function(ffi.Pointer<ffi.Void> data);
typedef Dartggml_abort_callbackFunction =
    bool Function(ffi.Pointer<ffi.Void> data);
typedef ggml_abort_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_abort_callbackFunction>>;

final class llama_context_params extends ffi.Struct {
  @ffi.Uint32()
  external int n_ctx;

  @ffi.Uint32()
  external int n_batch;

  @ffi.Uint32()
  external int n_ubatch;

  @ffi.Uint32()
  external int n_seq_max;

  @ffi.Int32()
  external int n_threads;

  @ffi.Int32()
  external int n_threads_batch;

  @ffi.Int()
  external int rope_scaling_typeAsInt;

  llama_rope_scaling_type get rope_scaling_type =>
      llama_rope_scaling_type.fromValue(rope_scaling_typeAsInt);

  @ffi.Int()
  external int pooling_typeAsInt;

  llama_pooling_type get pooling_type =>
      llama_pooling_type.fromValue(pooling_typeAsInt);

  @ffi.Int()
  external int attention_typeAsInt;

  llama_attention_type get attention_type =>
      llama_attention_type.fromValue(attention_typeAsInt);

  @ffi.Int()
  external int flash_attn_typeAsInt;

  llama_flash_attn_type get flash_attn_type =>
      llama_flash_attn_type.fromValue(flash_attn_typeAsInt);

  @ffi.Float()
  external double rope_freq_base;

  @ffi.Float()
  external double rope_freq_scale;

  @ffi.Float()
  external double yarn_ext_factor;

  @ffi.Float()
  external double yarn_attn_factor;

  @ffi.Float()
  external double yarn_beta_fast;

  @ffi.Float()
  external double yarn_beta_slow;

  @ffi.Uint32()
  external int yarn_orig_ctx;

  @ffi.Float()
  external double defrag_thold;

  external ggml_backend_sched_eval_callback cb_eval;

  external ffi.Pointer<ffi.Void> cb_eval_user_data;

  @ffi.UnsignedInt()
  external int type_kAsInt;

  ggml_type get type_k => ggml_type.fromValue(type_kAsInt);

  @ffi.UnsignedInt()
  external int type_vAsInt;

  ggml_type get type_v => ggml_type.fromValue(type_vAsInt);

  external ggml_abort_callback abort_callback;

  external ffi.Pointer<ffi.Void> abort_callback_data;

  @ffi.Bool()
  external bool embeddings;

  @ffi.Bool()
  external bool offload_kqv;

  @ffi.Bool()
  external bool no_perf;

  @ffi.Bool()
  external bool op_offload;

  @ffi.Bool()
  external bool swa_full;

  @ffi.Bool()
  external bool kv_unified;

  external ffi.Pointer<llama_sampler_seq_config> samplers;

  @ffi.Size()
  external int n_samplers;
}

final class llama_model_quantize_params extends ffi.Struct {
  @ffi.Int32()
  external int nthread;

  @ffi.UnsignedInt()
  external int ftypeAsInt;

  llama_ftype get ftype => llama_ftype.fromValue(ftypeAsInt);

  @ffi.UnsignedInt()
  external int output_tensor_typeAsInt;

  ggml_type get output_tensor_type =>
      ggml_type.fromValue(output_tensor_typeAsInt);

  @ffi.UnsignedInt()
  external int token_embedding_typeAsInt;

  ggml_type get token_embedding_type =>
      ggml_type.fromValue(token_embedding_typeAsInt);

  @ffi.Bool()
  external bool allow_requantize;

  @ffi.Bool()
  external bool quantize_output_tensor;

  @ffi.Bool()
  external bool only_copy;

  @ffi.Bool()
  external bool pure;

  @ffi.Bool()
  external bool keep_split;

  external ffi.Pointer<ffi.Void> imatrix;

  external ffi.Pointer<ffi.Void> kv_overrides;

  external ffi.Pointer<ffi.Void> tensor_types;

  external ffi.Pointer<ffi.Void> prune_layers;
}

final class llama_logit_bias extends ffi.Struct {
  @llama_token()
  external int token;

  @ffi.Float()
  external double bias;
}

final class llama_sampler_chain_params extends ffi.Struct {
  @ffi.Bool()
  external bool no_perf;
}

final class llama_chat_message extends ffi.Struct {
  external ffi.Pointer<ffi.Char> role;

  external ffi.Pointer<ffi.Char> content;
}

final class llama_adapter_lora extends ffi.Opaque {}

enum ggml_numa_strategy {
  GGML_NUMA_STRATEGY_DISABLED(0),
  GGML_NUMA_STRATEGY_DISTRIBUTE(1),
  GGML_NUMA_STRATEGY_ISOLATE(2),
  GGML_NUMA_STRATEGY_NUMACTL(3),
  GGML_NUMA_STRATEGY_MIRROR(4),
  GGML_NUMA_STRATEGY_COUNT(5);

  final int value;
  const ggml_numa_strategy(this.value);

  static ggml_numa_strategy fromValue(int value) => switch (value) {
    0 => GGML_NUMA_STRATEGY_DISABLED,
    1 => GGML_NUMA_STRATEGY_DISTRIBUTE,
    2 => GGML_NUMA_STRATEGY_ISOLATE,
    3 => GGML_NUMA_STRATEGY_NUMACTL,
    4 => GGML_NUMA_STRATEGY_MIRROR,
    5 => GGML_NUMA_STRATEGY_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_numa_strategy: $value'),
  };
}

final class ggml_threadpool extends ffi.Opaque {}

typedef ggml_threadpool_t = ffi.Pointer<ggml_threadpool>;

enum llama_params_fit_status {
  LLAMA_PARAMS_FIT_STATUS_SUCCESS(0),
  LLAMA_PARAMS_FIT_STATUS_FAILURE(1),
  LLAMA_PARAMS_FIT_STATUS_ERROR(2);

  final int value;
  const llama_params_fit_status(this.value);

  static llama_params_fit_status fromValue(int value) => switch (value) {
    0 => LLAMA_PARAMS_FIT_STATUS_SUCCESS,
    1 => LLAMA_PARAMS_FIT_STATUS_FAILURE,
    2 => LLAMA_PARAMS_FIT_STATUS_ERROR,
    _ => throw ArgumentError(
      'Unknown value for llama_params_fit_status: $value',
    ),
  };
}

enum ggml_log_level {
  GGML_LOG_LEVEL_NONE(0),
  GGML_LOG_LEVEL_DEBUG(1),
  GGML_LOG_LEVEL_INFO(2),
  GGML_LOG_LEVEL_WARN(3),
  GGML_LOG_LEVEL_ERROR(4),
  GGML_LOG_LEVEL_CONT(5);

  final int value;
  const ggml_log_level(this.value);

  static ggml_log_level fromValue(int value) => switch (value) {
    0 => GGML_LOG_LEVEL_NONE,
    1 => GGML_LOG_LEVEL_DEBUG,
    2 => GGML_LOG_LEVEL_INFO,
    3 => GGML_LOG_LEVEL_WARN,
    4 => GGML_LOG_LEVEL_ERROR,
    5 => GGML_LOG_LEVEL_CONT,
    _ => throw ArgumentError('Unknown value for ggml_log_level: $value'),
  };
}

typedef llama_state_seq_flags = ffi.Uint32;
typedef Dartllama_state_seq_flags = int;
typedef ggml_log_callbackFunction =
    ffi.Void Function(
      ffi.UnsignedInt level,
      ffi.Pointer<ffi.Char> text,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef Dartggml_log_callbackFunction =
    void Function(
      ggml_log_level level,
      ffi.Pointer<ffi.Char> text,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef ggml_log_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_log_callbackFunction>>;

final class llama_perf_context_data extends ffi.Struct {
  @ffi.Double()
  external double t_start_ms;

  @ffi.Double()
  external double t_load_ms;

  @ffi.Double()
  external double t_p_eval_ms;

  @ffi.Double()
  external double t_eval_ms;

  @ffi.Int32()
  external int n_p_eval;

  @ffi.Int32()
  external int n_eval;

  @ffi.Int32()
  external int n_reused;
}

final class llama_perf_sampler_data extends ffi.Struct {
  @ffi.Double()
  external double t_sample_ms;

  @ffi.Int32()
  external int n_sample;
}

typedef llama_opt_param_filterFunction =
    ffi.Bool Function(
      ffi.Pointer<ggml_tensor> tensor,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartllama_opt_param_filterFunction =
    bool Function(
      ffi.Pointer<ggml_tensor> tensor,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef llama_opt_param_filter =
    ffi.Pointer<ffi.NativeFunction<llama_opt_param_filterFunction>>;

final class UnnamedStruct extends ffi.Struct {
  @ffi.Float()
  external double alpha;

  @ffi.Float()
  external double beta1;

  @ffi.Float()
  external double beta2;

  @ffi.Float()
  external double eps;

  @ffi.Float()
  external double wd;
}

final class UnnamedStruct$1 extends ffi.Struct {
  @ffi.Float()
  external double alpha;

  @ffi.Float()
  external double wd;
}

final class ggml_opt_optimizer_params extends ffi.Struct {
  external UnnamedStruct adamw;

  external UnnamedStruct$1 sgd;
}

typedef ggml_opt_get_optimizer_paramsFunction =
    ggml_opt_optimizer_params Function(ffi.Pointer<ffi.Void> userdata);
typedef ggml_opt_get_optimizer_params =
    ffi.Pointer<ffi.NativeFunction<ggml_opt_get_optimizer_paramsFunction>>;

enum ggml_opt_optimizer_type {
  GGML_OPT_OPTIMIZER_TYPE_ADAMW(0),
  GGML_OPT_OPTIMIZER_TYPE_SGD(1),
  GGML_OPT_OPTIMIZER_TYPE_COUNT(2);

  final int value;
  const ggml_opt_optimizer_type(this.value);

  static ggml_opt_optimizer_type fromValue(int value) => switch (value) {
    0 => GGML_OPT_OPTIMIZER_TYPE_ADAMW,
    1 => GGML_OPT_OPTIMIZER_TYPE_SGD,
    2 => GGML_OPT_OPTIMIZER_TYPE_COUNT,
    _ => throw ArgumentError(
      'Unknown value for ggml_opt_optimizer_type: $value',
    ),
  };
}

final class llama_opt_params extends ffi.Struct {
  @ffi.Uint32()
  external int n_ctx_train;

  external llama_opt_param_filter param_filter;

  external ffi.Pointer<ffi.Void> param_filter_ud;

  external ggml_opt_get_optimizer_params get_opt_pars;

  external ffi.Pointer<ffi.Void> get_opt_pars_ud;

  @ffi.UnsignedInt()
  external int optimizer_typeAsInt;

  ggml_opt_optimizer_type get optimizer_type =>
      ggml_opt_optimizer_type.fromValue(optimizer_typeAsInt);
}

final class ggml_opt_dataset extends ffi.Opaque {}

typedef ggml_opt_dataset_t = ffi.Pointer<ggml_opt_dataset>;

final class ggml_opt_result extends ffi.Opaque {}

typedef ggml_opt_result_t = ffi.Pointer<ggml_opt_result>;

final class ggml_opt_context extends ffi.Opaque {}

typedef ggml_opt_context_t = ffi.Pointer<ggml_opt_context>;
typedef ggml_opt_epoch_callbackFunction =
    ffi.Void Function(
      ffi.Bool train,
      ggml_opt_context_t opt_ctx,
      ggml_opt_dataset_t dataset,
      ggml_opt_result_t result,
      ffi.Int64 ibatch,
      ffi.Int64 ibatch_max,
      ffi.Int64 t_start_us,
    );
typedef Dartggml_opt_epoch_callbackFunction =
    void Function(
      bool train,
      ggml_opt_context_t opt_ctx,
      ggml_opt_dataset_t dataset,
      ggml_opt_result_t result,
      int ibatch,
      int ibatch_max,
      int t_start_us,
    );
typedef ggml_opt_epoch_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_opt_epoch_callbackFunction>>;
typedef ggml_abort_callback_tFunction =
    ffi.Void Function(ffi.Pointer<ffi.Char> error_message);
typedef Dartggml_abort_callback_tFunction =
    void Function(ffi.Pointer<ffi.Char> error_message);
typedef ggml_abort_callback_t =
    ffi.Pointer<ffi.NativeFunction<ggml_abort_callback_tFunction>>;

enum ggml_status {
  GGML_STATUS_ALLOC_FAILED(-2),
  GGML_STATUS_FAILED(-1),
  GGML_STATUS_SUCCESS(0),
  GGML_STATUS_ABORTED(1);

  final int value;
  const ggml_status(this.value);

  static ggml_status fromValue(int value) => switch (value) {
    -2 => GGML_STATUS_ALLOC_FAILED,
    -1 => GGML_STATUS_FAILED,
    0 => GGML_STATUS_SUCCESS,
    1 => GGML_STATUS_ABORTED,
    _ => throw ArgumentError('Unknown value for ggml_status: $value'),
  };
}

typedef ggml_fp16_t = ffi.Uint16;
typedef Dartggml_fp16_t = int;

final class ggml_bf16_t extends ffi.Struct {
  @ffi.Uint16()
  external int bits;
}

final class ggml_object extends ffi.Opaque {}

enum ggml_prec {
  GGML_PREC_DEFAULT(0),
  GGML_PREC_F32(10);

  final int value;
  const ggml_prec(this.value);

  static ggml_prec fromValue(int value) => switch (value) {
    0 => GGML_PREC_DEFAULT,
    10 => GGML_PREC_F32,
    _ => throw ArgumentError('Unknown value for ggml_prec: $value'),
  };
}

enum ggml_ftype {
  GGML_FTYPE_UNKNOWN(-1),
  GGML_FTYPE_ALL_F32(0),
  GGML_FTYPE_MOSTLY_F16(1),
  GGML_FTYPE_MOSTLY_Q4_0(2),
  GGML_FTYPE_MOSTLY_Q4_1(3),
  GGML_FTYPE_MOSTLY_Q4_1_SOME_F16(4),
  GGML_FTYPE_MOSTLY_Q8_0(7),
  GGML_FTYPE_MOSTLY_Q5_0(8),
  GGML_FTYPE_MOSTLY_Q5_1(9),
  GGML_FTYPE_MOSTLY_Q2_K(10),
  GGML_FTYPE_MOSTLY_Q3_K(11),
  GGML_FTYPE_MOSTLY_Q4_K(12),
  GGML_FTYPE_MOSTLY_Q5_K(13),
  GGML_FTYPE_MOSTLY_Q6_K(14),
  GGML_FTYPE_MOSTLY_IQ2_XXS(15),
  GGML_FTYPE_MOSTLY_IQ2_XS(16),
  GGML_FTYPE_MOSTLY_IQ3_XXS(17),
  GGML_FTYPE_MOSTLY_IQ1_S(18),
  GGML_FTYPE_MOSTLY_IQ4_NL(19),
  GGML_FTYPE_MOSTLY_IQ3_S(20),
  GGML_FTYPE_MOSTLY_IQ2_S(21),
  GGML_FTYPE_MOSTLY_IQ4_XS(22),
  GGML_FTYPE_MOSTLY_IQ1_M(23),
  GGML_FTYPE_MOSTLY_BF16(24),
  GGML_FTYPE_MOSTLY_MXFP4(25);

  final int value;
  const ggml_ftype(this.value);

  static ggml_ftype fromValue(int value) => switch (value) {
    -1 => GGML_FTYPE_UNKNOWN,
    0 => GGML_FTYPE_ALL_F32,
    1 => GGML_FTYPE_MOSTLY_F16,
    2 => GGML_FTYPE_MOSTLY_Q4_0,
    3 => GGML_FTYPE_MOSTLY_Q4_1,
    4 => GGML_FTYPE_MOSTLY_Q4_1_SOME_F16,
    7 => GGML_FTYPE_MOSTLY_Q8_0,
    8 => GGML_FTYPE_MOSTLY_Q5_0,
    9 => GGML_FTYPE_MOSTLY_Q5_1,
    10 => GGML_FTYPE_MOSTLY_Q2_K,
    11 => GGML_FTYPE_MOSTLY_Q3_K,
    12 => GGML_FTYPE_MOSTLY_Q4_K,
    13 => GGML_FTYPE_MOSTLY_Q5_K,
    14 => GGML_FTYPE_MOSTLY_Q6_K,
    15 => GGML_FTYPE_MOSTLY_IQ2_XXS,
    16 => GGML_FTYPE_MOSTLY_IQ2_XS,
    17 => GGML_FTYPE_MOSTLY_IQ3_XXS,
    18 => GGML_FTYPE_MOSTLY_IQ1_S,
    19 => GGML_FTYPE_MOSTLY_IQ4_NL,
    20 => GGML_FTYPE_MOSTLY_IQ3_S,
    21 => GGML_FTYPE_MOSTLY_IQ2_S,
    22 => GGML_FTYPE_MOSTLY_IQ4_XS,
    23 => GGML_FTYPE_MOSTLY_IQ1_M,
    24 => GGML_FTYPE_MOSTLY_BF16,
    25 => GGML_FTYPE_MOSTLY_MXFP4,
    _ => throw ArgumentError('Unknown value for ggml_ftype: $value'),
  };
}

enum ggml_unary_op {
  GGML_UNARY_OP_ABS(0),
  GGML_UNARY_OP_SGN(1),
  GGML_UNARY_OP_NEG(2),
  GGML_UNARY_OP_STEP(3),
  GGML_UNARY_OP_TANH(4),
  GGML_UNARY_OP_ELU(5),
  GGML_UNARY_OP_RELU(6),
  GGML_UNARY_OP_SIGMOID(7),
  GGML_UNARY_OP_GELU(8),
  GGML_UNARY_OP_GELU_QUICK(9),
  GGML_UNARY_OP_SILU(10),
  GGML_UNARY_OP_HARDSWISH(11),
  GGML_UNARY_OP_HARDSIGMOID(12),
  GGML_UNARY_OP_EXP(13),
  GGML_UNARY_OP_EXPM1(14),
  GGML_UNARY_OP_SOFTPLUS(15),
  GGML_UNARY_OP_GELU_ERF(16),
  GGML_UNARY_OP_XIELU(17),
  GGML_UNARY_OP_FLOOR(18),
  GGML_UNARY_OP_CEIL(19),
  GGML_UNARY_OP_ROUND(20),
  GGML_UNARY_OP_TRUNC(21),
  GGML_UNARY_OP_COUNT(22);

  final int value;
  const ggml_unary_op(this.value);

  static ggml_unary_op fromValue(int value) => switch (value) {
    0 => GGML_UNARY_OP_ABS,
    1 => GGML_UNARY_OP_SGN,
    2 => GGML_UNARY_OP_NEG,
    3 => GGML_UNARY_OP_STEP,
    4 => GGML_UNARY_OP_TANH,
    5 => GGML_UNARY_OP_ELU,
    6 => GGML_UNARY_OP_RELU,
    7 => GGML_UNARY_OP_SIGMOID,
    8 => GGML_UNARY_OP_GELU,
    9 => GGML_UNARY_OP_GELU_QUICK,
    10 => GGML_UNARY_OP_SILU,
    11 => GGML_UNARY_OP_HARDSWISH,
    12 => GGML_UNARY_OP_HARDSIGMOID,
    13 => GGML_UNARY_OP_EXP,
    14 => GGML_UNARY_OP_EXPM1,
    15 => GGML_UNARY_OP_SOFTPLUS,
    16 => GGML_UNARY_OP_GELU_ERF,
    17 => GGML_UNARY_OP_XIELU,
    18 => GGML_UNARY_OP_FLOOR,
    19 => GGML_UNARY_OP_CEIL,
    20 => GGML_UNARY_OP_ROUND,
    21 => GGML_UNARY_OP_TRUNC,
    22 => GGML_UNARY_OP_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_unary_op: $value'),
  };
}

enum ggml_glu_op {
  GGML_GLU_OP_REGLU(0),
  GGML_GLU_OP_GEGLU(1),
  GGML_GLU_OP_SWIGLU(2),
  GGML_GLU_OP_SWIGLU_OAI(3),
  GGML_GLU_OP_GEGLU_ERF(4),
  GGML_GLU_OP_GEGLU_QUICK(5),
  GGML_GLU_OP_COUNT(6);

  final int value;
  const ggml_glu_op(this.value);

  static ggml_glu_op fromValue(int value) => switch (value) {
    0 => GGML_GLU_OP_REGLU,
    1 => GGML_GLU_OP_GEGLU,
    2 => GGML_GLU_OP_SWIGLU,
    3 => GGML_GLU_OP_SWIGLU_OAI,
    4 => GGML_GLU_OP_GEGLU_ERF,
    5 => GGML_GLU_OP_GEGLU_QUICK,
    6 => GGML_GLU_OP_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_glu_op: $value'),
  };
}

enum ggml_object_type {
  GGML_OBJECT_TYPE_TENSOR(0),
  GGML_OBJECT_TYPE_GRAPH(1),
  GGML_OBJECT_TYPE_WORK_BUFFER(2);

  final int value;
  const ggml_object_type(this.value);

  static ggml_object_type fromValue(int value) => switch (value) {
    0 => GGML_OBJECT_TYPE_TENSOR,
    1 => GGML_OBJECT_TYPE_GRAPH,
    2 => GGML_OBJECT_TYPE_WORK_BUFFER,
    _ => throw ArgumentError('Unknown value for ggml_object_type: $value'),
  };
}

enum ggml_tensor_flag {
  GGML_TENSOR_FLAG_INPUT(1),
  GGML_TENSOR_FLAG_OUTPUT(2),
  GGML_TENSOR_FLAG_PARAM(4),
  GGML_TENSOR_FLAG_LOSS(8),
  GGML_TENSOR_FLAG_COMPUTE(16);

  final int value;
  const ggml_tensor_flag(this.value);

  static ggml_tensor_flag fromValue(int value) => switch (value) {
    1 => GGML_TENSOR_FLAG_INPUT,
    2 => GGML_TENSOR_FLAG_OUTPUT,
    4 => GGML_TENSOR_FLAG_PARAM,
    8 => GGML_TENSOR_FLAG_LOSS,
    16 => GGML_TENSOR_FLAG_COMPUTE,
    _ => throw ArgumentError('Unknown value for ggml_tensor_flag: $value'),
  };
}

enum ggml_tri_type {
  GGML_TRI_TYPE_UPPER_DIAG(0),
  GGML_TRI_TYPE_UPPER(1),
  GGML_TRI_TYPE_LOWER_DIAG(2),
  GGML_TRI_TYPE_LOWER(3);

  final int value;
  const ggml_tri_type(this.value);

  static ggml_tri_type fromValue(int value) => switch (value) {
    0 => GGML_TRI_TYPE_UPPER_DIAG,
    1 => GGML_TRI_TYPE_UPPER,
    2 => GGML_TRI_TYPE_LOWER_DIAG,
    3 => GGML_TRI_TYPE_LOWER,
    _ => throw ArgumentError('Unknown value for ggml_tri_type: $value'),
  };
}

final class ggml_init_params extends ffi.Struct {
  @ffi.Size()
  external int mem_size;

  external ffi.Pointer<ffi.Void> mem_buffer;

  @ffi.Bool()
  external bool no_alloc;
}

typedef ggml_guid_t = ffi.Pointer<ffi.Pointer<ffi.Uint8>>;

final class _IO_marker extends ffi.Opaque {}

typedef __off_t = ffi.Long;
typedef Dart__off_t = int;
typedef _IO_lock_t = ffi.Void;
typedef Dart_IO_lock_t = void;
typedef __off64_t = ffi.Long;
typedef Dart__off64_t = int;

final class _IO_codecvt extends ffi.Opaque {}

final class _IO_wide_data extends ffi.Opaque {}

final class _IO_FILE extends ffi.Struct {
  @ffi.Int()
  external int _flags;

  external ffi.Pointer<ffi.Char> _IO_read_ptr;

  external ffi.Pointer<ffi.Char> _IO_read_end;

  external ffi.Pointer<ffi.Char> _IO_read_base;

  external ffi.Pointer<ffi.Char> _IO_write_base;

  external ffi.Pointer<ffi.Char> _IO_write_ptr;

  external ffi.Pointer<ffi.Char> _IO_write_end;

  external ffi.Pointer<ffi.Char> _IO_buf_base;

  external ffi.Pointer<ffi.Char> _IO_buf_end;

  external ffi.Pointer<ffi.Char> _IO_save_base;

  external ffi.Pointer<ffi.Char> _IO_backup_base;

  external ffi.Pointer<ffi.Char> _IO_save_end;

  external ffi.Pointer<_IO_marker> _markers;

  external ffi.Pointer<_IO_FILE> _chain;

  @ffi.Int()
  external int _fileno;

  @ffi.Int()
  external int _flags2;

  @__off_t()
  external int _old_offset;

  @ffi.UnsignedShort()
  external int _cur_column;

  @ffi.SignedChar()
  external int _vtable_offset;

  @ffi.Array.multi([1])
  external ffi.Array<ffi.Char> _shortbuf;

  external ffi.Pointer<_IO_lock_t> _lock;

  @__off64_t()
  external int _offset;

  external ffi.Pointer<_IO_codecvt> _codecvt;

  external ffi.Pointer<_IO_wide_data> _wide_data;

  external ffi.Pointer<_IO_FILE> _freeres_list;

  external ffi.Pointer<ffi.Void> _freeres_buf;

  @ffi.Size()
  external int __pad5;

  @ffi.Int()
  external int _mode;

  @ffi.Array.multi([20])
  external ffi.Array<ffi.Char> _unused2;
}

typedef FILE = _IO_FILE;

enum ggml_op_pool {
  GGML_OP_POOL_MAX(0),
  GGML_OP_POOL_AVG(1),
  GGML_OP_POOL_COUNT(2);

  final int value;
  const ggml_op_pool(this.value);

  static ggml_op_pool fromValue(int value) => switch (value) {
    0 => GGML_OP_POOL_MAX,
    1 => GGML_OP_POOL_AVG,
    2 => GGML_OP_POOL_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_op_pool: $value'),
  };
}

enum ggml_scale_mode {
  GGML_SCALE_MODE_NEAREST(0),
  GGML_SCALE_MODE_BILINEAR(1),
  GGML_SCALE_MODE_BICUBIC(2),
  GGML_SCALE_MODE_COUNT(3);

  final int value;
  const ggml_scale_mode(this.value);

  static ggml_scale_mode fromValue(int value) => switch (value) {
    0 => GGML_SCALE_MODE_NEAREST,
    1 => GGML_SCALE_MODE_BILINEAR,
    2 => GGML_SCALE_MODE_BICUBIC,
    3 => GGML_SCALE_MODE_COUNT,
    _ => throw ArgumentError('Unknown value for ggml_scale_mode: $value'),
  };
}

enum ggml_scale_flag {
  GGML_SCALE_FLAG_ALIGN_CORNERS(256),
  GGML_SCALE_FLAG_ANTIALIAS(512);

  final int value;
  const ggml_scale_flag(this.value);

  static ggml_scale_flag fromValue(int value) => switch (value) {
    256 => GGML_SCALE_FLAG_ALIGN_CORNERS,
    512 => GGML_SCALE_FLAG_ANTIALIAS,
    _ => throw ArgumentError('Unknown value for ggml_scale_flag: $value'),
  };
}

enum ggml_sort_order {
  GGML_SORT_ORDER_ASC(0),
  GGML_SORT_ORDER_DESC(1);

  final int value;
  const ggml_sort_order(this.value);

  static ggml_sort_order fromValue(int value) => switch (value) {
    0 => GGML_SORT_ORDER_ASC,
    1 => GGML_SORT_ORDER_DESC,
    _ => throw ArgumentError('Unknown value for ggml_sort_order: $value'),
  };
}

typedef ggml_custom1_op_tFunction =
    ffi.Void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      ffi.Int ith,
      ffi.Int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartggml_custom1_op_tFunction =
    void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      int ith,
      int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef ggml_custom1_op_t =
    ffi.Pointer<ffi.NativeFunction<ggml_custom1_op_tFunction>>;
typedef ggml_custom2_op_tFunction =
    ffi.Void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      ffi.Pointer<ggml_tensor> b,
      ffi.Int ith,
      ffi.Int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartggml_custom2_op_tFunction =
    void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      ffi.Pointer<ggml_tensor> b,
      int ith,
      int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef ggml_custom2_op_t =
    ffi.Pointer<ffi.NativeFunction<ggml_custom2_op_tFunction>>;
typedef ggml_custom3_op_tFunction =
    ffi.Void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      ffi.Pointer<ggml_tensor> b,
      ffi.Pointer<ggml_tensor> c,
      ffi.Int ith,
      ffi.Int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartggml_custom3_op_tFunction =
    void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Pointer<ggml_tensor> a,
      ffi.Pointer<ggml_tensor> b,
      ffi.Pointer<ggml_tensor> c,
      int ith,
      int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef ggml_custom3_op_t =
    ffi.Pointer<ffi.NativeFunction<ggml_custom3_op_tFunction>>;
typedef ggml_custom_op_tFunction =
    ffi.Void Function(
      ffi.Pointer<ggml_tensor> dst,
      ffi.Int ith,
      ffi.Int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef Dartggml_custom_op_tFunction =
    void Function(
      ffi.Pointer<ggml_tensor> dst,
      int ith,
      int nth,
      ffi.Pointer<ffi.Void> userdata,
    );
typedef ggml_custom_op_t =
    ffi.Pointer<ffi.NativeFunction<ggml_custom_op_tFunction>>;
typedef ggml_to_float_tFunction =
    ffi.Void Function(
      ffi.Pointer<ffi.Void> x,
      ffi.Pointer<ffi.Float> y,
      ffi.Int64 k,
    );
typedef Dartggml_to_float_tFunction =
    void Function(ffi.Pointer<ffi.Void> x, ffi.Pointer<ffi.Float> y, int k);
typedef ggml_to_float_t =
    ffi.Pointer<ffi.NativeFunction<ggml_to_float_tFunction>>;
typedef ggml_from_float_tFunction =
    ffi.Void Function(
      ffi.Pointer<ffi.Float> x,
      ffi.Pointer<ffi.Void> y,
      ffi.Int64 k,
    );
typedef Dartggml_from_float_tFunction =
    void Function(ffi.Pointer<ffi.Float> x, ffi.Pointer<ffi.Void> y, int k);
typedef ggml_from_float_t =
    ffi.Pointer<ffi.NativeFunction<ggml_from_float_tFunction>>;

final class ggml_type_traits extends ffi.Struct {
  external ffi.Pointer<ffi.Char> type_name;

  @ffi.Int64()
  external int blck_size;

  @ffi.Int64()
  external int blck_size_interleave;

  @ffi.Size()
  external int type_size;

  @ffi.Bool()
  external bool is_quantized;

  external ggml_to_float_t to_float;

  external ggml_from_float_t from_float_ref;
}

enum ggml_sched_priority {
  GGML_SCHED_PRIO_LOW(-1),
  GGML_SCHED_PRIO_NORMAL(0),
  GGML_SCHED_PRIO_MEDIUM(1),
  GGML_SCHED_PRIO_HIGH(2),
  GGML_SCHED_PRIO_REALTIME(3);

  final int value;
  const ggml_sched_priority(this.value);

  static ggml_sched_priority fromValue(int value) => switch (value) {
    -1 => GGML_SCHED_PRIO_LOW,
    0 => GGML_SCHED_PRIO_NORMAL,
    1 => GGML_SCHED_PRIO_MEDIUM,
    2 => GGML_SCHED_PRIO_HIGH,
    3 => GGML_SCHED_PRIO_REALTIME,
    _ => throw ArgumentError('Unknown value for ggml_sched_priority: $value'),
  };
}

final class ggml_threadpool_params extends ffi.Struct {
  @ffi.Array.multi([512])
  external ffi.Array<ffi.Bool> cpumask;

  @ffi.Int()
  external int n_threads;

  @ffi.Int()
  external int prioAsInt;

  ggml_sched_priority get prio => ggml_sched_priority.fromValue(prioAsInt);

  @ffi.Uint32()
  external int poll;

  @ffi.Bool()
  external bool strict_cpu;

  @ffi.Bool()
  external bool paused;
}

typedef ggml_backend_buffer_t = ffi.Pointer<ggml_backend_buffer>;

final class ggml_backend_event extends ffi.Opaque {}

typedef ggml_backend_event_t = ffi.Pointer<ggml_backend_event>;

final class ggml_backend extends ffi.Opaque {}

typedef ggml_backend_t = ffi.Pointer<ggml_backend>;
typedef ggml_backend_graph_plan_t = ffi.Pointer<ffi.Void>;

final class ggml_backend_reg extends ffi.Opaque {}

typedef ggml_backend_reg_t = ffi.Pointer<ggml_backend_reg>;

enum ggml_backend_buffer_usage {
  GGML_BACKEND_BUFFER_USAGE_ANY(0),
  GGML_BACKEND_BUFFER_USAGE_WEIGHTS(1),
  GGML_BACKEND_BUFFER_USAGE_COMPUTE(2);

  final int value;
  const ggml_backend_buffer_usage(this.value);

  static ggml_backend_buffer_usage fromValue(int value) => switch (value) {
    0 => GGML_BACKEND_BUFFER_USAGE_ANY,
    1 => GGML_BACKEND_BUFFER_USAGE_WEIGHTS,
    2 => GGML_BACKEND_BUFFER_USAGE_COMPUTE,
    _ => throw ArgumentError(
      'Unknown value for ggml_backend_buffer_usage: $value',
    ),
  };
}

enum ggml_backend_dev_type {
  GGML_BACKEND_DEVICE_TYPE_CPU(0),
  GGML_BACKEND_DEVICE_TYPE_GPU(1),
  GGML_BACKEND_DEVICE_TYPE_IGPU(2),
  GGML_BACKEND_DEVICE_TYPE_ACCEL(3);

  final int value;
  const ggml_backend_dev_type(this.value);

  static ggml_backend_dev_type fromValue(int value) => switch (value) {
    0 => GGML_BACKEND_DEVICE_TYPE_CPU,
    1 => GGML_BACKEND_DEVICE_TYPE_GPU,
    2 => GGML_BACKEND_DEVICE_TYPE_IGPU,
    3 => GGML_BACKEND_DEVICE_TYPE_ACCEL,
    _ => throw ArgumentError('Unknown value for ggml_backend_dev_type: $value'),
  };
}

final class ggml_backend_dev_caps extends ffi.Struct {
  @ffi.Bool()
  external bool async;

  @ffi.Bool()
  external bool host_buffer;

  @ffi.Bool()
  external bool buffer_from_host_ptr;

  @ffi.Bool()
  external bool events;
}

final class ggml_backend_dev_props extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  external ffi.Pointer<ffi.Char> description;

  @ffi.Size()
  external int memory_free;

  @ffi.Size()
  external int memory_total;

  @ffi.UnsignedInt()
  external int typeAsInt;

  ggml_backend_dev_type get type => ggml_backend_dev_type.fromValue(typeAsInt);

  external ffi.Pointer<ffi.Char> device_id;

  external ggml_backend_dev_caps caps;
}

typedef ggml_backend_split_buffer_type_tFunction =
    ggml_backend_buffer_type_t Function(
      ffi.Int main_device,
      ffi.Pointer<ffi.Float> tensor_split,
    );
typedef Dartggml_backend_split_buffer_type_tFunction =
    ggml_backend_buffer_type_t Function(
      int main_device,
      ffi.Pointer<ffi.Float> tensor_split,
    );
typedef ggml_backend_split_buffer_type_t =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_split_buffer_type_tFunction>>;
typedef ggml_backend_set_n_threads_tFunction =
    ffi.Void Function(ggml_backend_t backend, ffi.Int n_threads);
typedef Dartggml_backend_set_n_threads_tFunction =
    void Function(ggml_backend_t backend, int n_threads);
typedef ggml_backend_set_n_threads_t =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_set_n_threads_tFunction>>;
typedef ggml_backend_dev_get_extra_bufts_tFunction =
    ffi.Pointer<ggml_backend_buffer_type_t> Function(ggml_backend_dev_t device);
typedef ggml_backend_dev_get_extra_bufts_t =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_dev_get_extra_bufts_tFunction>>;
typedef ggml_backend_set_abort_callback_tFunction =
    ffi.Void Function(
      ggml_backend_t backend,
      ggml_abort_callback abort_callback,
      ffi.Pointer<ffi.Void> abort_callback_data,
    );
typedef Dartggml_backend_set_abort_callback_tFunction =
    void Function(
      ggml_backend_t backend,
      ggml_abort_callback abort_callback,
      ffi.Pointer<ffi.Void> abort_callback_data,
    );
typedef ggml_backend_set_abort_callback_t =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_set_abort_callback_tFunction>>;

final class ggml_backend_feature extends ffi.Struct {
  external ffi.Pointer<ffi.Char> name;

  external ffi.Pointer<ffi.Char> value;
}

typedef ggml_backend_get_features_tFunction =
    ffi.Pointer<ggml_backend_feature> Function(ggml_backend_reg_t reg);
typedef ggml_backend_get_features_t =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_get_features_tFunction>>;

final class ggml_backend_sched extends ffi.Opaque {}

typedef ggml_backend_sched_t = ffi.Pointer<ggml_backend_sched>;

final class ggml_backend_graph_copy$1 extends ffi.Struct {
  external ggml_backend_buffer_t buffer;

  external ffi.Pointer<ggml_context> ctx_allocated;

  external ffi.Pointer<ggml_context> ctx_unallocated;

  external ffi.Pointer<ggml_cgraph> graph;
}

typedef ggml_backend_eval_callbackFunction =
    ffi.Bool Function(
      ffi.Int node_index,
      ffi.Pointer<ggml_tensor> t1,
      ffi.Pointer<ggml_tensor> t2,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef Dartggml_backend_eval_callbackFunction =
    bool Function(
      int node_index,
      ffi.Pointer<ggml_tensor> t1,
      ffi.Pointer<ggml_tensor> t2,
      ffi.Pointer<ffi.Void> user_data,
    );
typedef ggml_backend_eval_callback =
    ffi.Pointer<ffi.NativeFunction<ggml_backend_eval_callbackFunction>>;

enum mtmd_input_chunk_type {
  MTMD_INPUT_CHUNK_TYPE_TEXT(0),
  MTMD_INPUT_CHUNK_TYPE_IMAGE(1),
  MTMD_INPUT_CHUNK_TYPE_AUDIO(2);

  final int value;
  const mtmd_input_chunk_type(this.value);

  static mtmd_input_chunk_type fromValue(int value) => switch (value) {
    0 => MTMD_INPUT_CHUNK_TYPE_TEXT,
    1 => MTMD_INPUT_CHUNK_TYPE_IMAGE,
    2 => MTMD_INPUT_CHUNK_TYPE_AUDIO,
    _ => throw ArgumentError('Unknown value for mtmd_input_chunk_type: $value'),
  };
}

final class mtmd_context extends ffi.Opaque {}

final class mtmd_bitmap extends ffi.Opaque {}

final class mtmd_image_tokens extends ffi.Opaque {}

final class mtmd_input_chunk extends ffi.Opaque {}

final class mtmd_input_chunks extends ffi.Opaque {}

final class mtmd_input_text extends ffi.Struct {
  external ffi.Pointer<ffi.Char> text;

  @ffi.Bool()
  external bool add_special;

  @ffi.Bool()
  external bool parse_special;
}

final class mtmd_context_params extends ffi.Struct {
  @ffi.Bool()
  external bool use_gpu;

  @ffi.Bool()
  external bool print_timings;

  @ffi.Int()
  external int n_threads;

  external ffi.Pointer<ffi.Char> image_marker;

  external ffi.Pointer<ffi.Char> media_marker;

  @ffi.Int()
  external int flash_attn_typeAsInt;

  llama_flash_attn_type get flash_attn_type =>
      llama_flash_attn_type.fromValue(flash_attn_typeAsInt);

  @ffi.Bool()
  external bool warmup;

  @ffi.Int()
  external int image_min_tokens;

  @ffi.Int()
  external int image_max_tokens;

  external ggml_backend_sched_eval_callback cb_eval;

  external ffi.Pointer<ffi.Void> cb_eval_user_data;
}

const int LLAMA_DEFAULT_SEED = 4294967295;

const int LLAMA_TOKEN_NULL = -1;

const int LLAMA_FILE_MAGIC_GGLA = 1734831201;

const int LLAMA_FILE_MAGIC_GGSN = 1734833006;

const int LLAMA_FILE_MAGIC_GGSQ = 1734833009;

const int LLAMA_SESSION_MAGIC = 1734833006;

const int LLAMA_SESSION_VERSION = 9;

const int LLAMA_STATE_SEQ_MAGIC = 1734833009;

const int LLAMA_STATE_SEQ_VERSION = 2;

const int LLAMA_STATE_SEQ_FLAGS_SWA_ONLY = 1;

const int LLAMA_STATE_SEQ_FLAGS_PARTIAL_ONLY = 1;

const int GGML_FILE_MAGIC = 1734831468;

const int GGML_FILE_VERSION = 2;

const int GGML_QNT_VERSION = 2;

const int GGML_QNT_VERSION_FACTOR = 1000;

const int GGML_MAX_DIMS = 4;

const int GGML_MAX_PARAMS = 2048;

const int GGML_MAX_SRC = 10;

const int GGML_MAX_N_THREADS = 512;

const int GGML_MAX_OP_PARAMS = 64;

const int GGML_MAX_NAME = 64;

const int GGML_DEFAULT_N_THREADS = 4;

const int GGML_DEFAULT_GRAPH_SIZE = 2048;

const int GGML_MEM_ALIGN = 16;

const int GGML_EXIT_SUCCESS = 0;

const int GGML_EXIT_ABORTED = 1;

const int GGML_ROPE_TYPE_NORMAL = 0;

const int GGML_ROPE_TYPE_NEOX = 2;

const int GGML_ROPE_TYPE_MROPE = 8;

const int GGML_ROPE_TYPE_VISION = 24;

const int GGML_ROPE_TYPE_IMROPE = 40;

const int GGML_MROPE_SECTIONS = 4;

const int GGML_N_TASKS_MAX = -1;

const String MTMD_DEFAULT_IMAGE_MARKER = '<__image__>';
